{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Нейронные сети: зависимость ошибки и обучающей способности от числа нейронов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом задании вы будете настраивать двуслойную нейронную сеть для решения задачи многоклассовой классификации. Предлагается выполнить процедуры загрузки и разбиения входных данных, обучения сети и подсчета ошибки классификации. Предлагается определить оптимальное количество нейронов в скрытом слое сети. Нужно так подобрать число нейронов, чтобы модель была с одной стороны несложной, а с другой стороны давала бы достаточно точный прогноз и не переобучалась. Цель задания -- показать, как зависит точность и обучающая способность сети от ее сложности."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для решения задачи многоклассовой классификации предлагается воспользоваться библиотекой построения нейронных сетей [pybrain](http://pybrain.org/). Библиотека содержит основные модули инициализации двуслойной нейронной сети прямого распространения, оценки ее параметров с помощью метода обратного распространения ошибки (backpropagation) и подсчета ошибки.\n",
    "\n",
    "Установить библиотеку pybrain можно с помощью стандартной системы управления пакетами pip:\n",
    "\n",
    "```\n",
    "pip install pybrain\n",
    "```\n",
    "Кроме того, для установки библиотеки можно использовать и другие способы, приведенные в [документации](https://github.com/pybrain/pybrain/wiki/installation). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Используемые данные\n",
    "\n",
    "Рассматривается задача оценки качества вина по его физико-химическим свойствам [1]. Данные размещены в [открытом доступе](https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv) в репозитории UCI  и содержат 1599 образцов красного вина, описанных 11 признаками, среди которых -- кислотность, процентное содержание сахара, алкоголя и пр. Кроме того, каждому объекту поставлена в соответствие оценка качества по шкале от 0 до 10. Требуется восстановить оценку качества вина по исходному признаковому описанию.\n",
    "\n",
    "[1] P. Cortez, A. Cerdeira, F. Almeida, T. Matos and J. Reis. Modeling wine preferences by data mining from physicochemical properties.  In Decision Support Systems, Elsevier, 47(4):547-553, 2009. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting https://github.com/pybrain/pybrain/archive/0.3.3.zip\n",
      "  Using cached https://github.com/pybrain/pybrain/archive/0.3.3.zip\n",
      "Requirement already satisfied (use --upgrade to upgrade): PyBrain==0.3.1 from https://github.com/pybrain/pybrain/archive/0.3.3.zip in c:\\users\\kir\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\n",
      "Requirement already satisfied: scipy in c:\\users\\kir\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from PyBrain==0.3.1) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.8.2 in c:\\users\\kir\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from scipy->PyBrain==0.3.1) (1.16.4)\n",
      "Building wheels for collected packages: PyBrain\n",
      "  Building wheel for PyBrain (setup.py): started\n",
      "  Building wheel for PyBrain (setup.py): finished with status 'done'\n",
      "  Created wheel for PyBrain: filename=PyBrain-0.3.1-py3-none-any.whl size=468238 sha256=bd3a18209ce4cdd094750553d92a23660d64afad9b47c904412a4ef7b1e3eeaa\n",
      "  Stored in directory: C:\\Users\\Kir\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-oxl_rl1r\\wheels\\c7\\56\\4e\\56d3dbbc48a90306f3ac2cc356de1d6d327090889fc0b29c6f\n",
      "Successfully built PyBrain\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.0.2; however, version 20.2.2 is available.\n",
      "You should consider upgrading via the 'c:\\users\\kir\\appdata\\local\\programs\\python\\python37\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scipy in c:\\users\\kir\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.8.2 in c:\\users\\kir\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from scipy) (1.16.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.0.2; however, version 20.2.2 is available.\n",
      "You should consider upgrading via the 'c:\\users\\kir\\appdata\\local\\programs\\python\\python37\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install https://github.com/pybrain/pybrain/archive/0.3.3.zip\n",
    "!pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выполним инициализацию основных используемых модулей\n",
    "%matplotlib inline\n",
    "\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import normalize\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполним загрузку данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('winequality-red.csv') as f:\n",
    "    f.readline()  # пропуск заголовочной строки\n",
    "    data = np.loadtxt(f, delimiter=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве альтернативного варианта, можно выполнить загрузку данных напрямую из репозитория UCI, воспользовавшись библиотекой urllib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "# URL for the Wine Quality Data Set (UCI Machine Learning Repository)\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\"\n",
    "# загрузка файла\n",
    "f = urllib.urlopen(url)\n",
    "f.readline()  # пропуск заголовочной строки\n",
    "data = np.loadtxt(f, delimiter=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выделим из данных целевую переменную. Классы в задаче являются несбалинсированными: основной доле объектов поставлена оценка качества от 5 до 7. Приведем задачу к трехклассовой: объектам с оценкой качества меньше пяти поставим оценку 5, а объектам с оценкой качества больше семи поставим 7. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SIZE = 0.7 # Разделение данных на обучающую и контрольную части в пропорции 70/30%\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = data[:, -1]\n",
    "np.place(y, y < 5, 5)\n",
    "np.place(y, y > 7, 7)\n",
    "y -= min(y)\n",
    "X = data[:, :-1]\n",
    "X = normalize(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=TRAIN_SIZE, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Двуслойная нейронная сеть\n",
    "\n",
    "Двуслойная нейронная сеть представляет собой функцию распознавания, которая може быть записана в виде следующей суперпозиции:\n",
    "\n",
    "$f(x,W)=h^{(2)}\\left(\\sum\\limits_{i=1}^D w_i^{(2)}h^{(1)}\\left(\\sum\\limits_{j=1}^n w_{ji}^{(1)}x_j+b_i^{(1)}\\right)+b^{(2)}\\right)$, где\n",
    "\n",
    "$x$ -- исходный объект (сорт вина, описанный 11 признаками), $x_j$ -- соответствующий признак,\n",
    "\n",
    "$n$ --  количество нейронов во входном слое сети, совпадающее с количеством признаков,\n",
    "\n",
    "$D$ --  количество нейронов в скрытом слое сети,\n",
    "\n",
    "$w_i^{(2)}, w_{ji}^{(1)}, b_i^{(1)}, b^{(2)}$ --  параметры сети, соответствующие весам нейронов,\n",
    "\n",
    "$h^{(1)}, h^{(2)}$ -- функции активации.\n",
    "\n",
    "В качестве функции активации на скрытом слое сети используется линейная функция. На выходном слое сети используется функция активации softmax, являющаяся обобщением сигмоидной функции на многоклассовый случай:\n",
    "\n",
    "$y_k=\\text{softmax}_k(a_1,...,a_k)=\\frac{\\exp(a_k)}{\\sum_{k=1}^K\\exp(a_k)}.$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Настройка параметров сети\n",
    "\n",
    "Оптимальные параметры сети $W_{opt}$ определяются путем минимизации функции ошибки:\n",
    "\n",
    "$W_{opt}=\\arg\\min\\limits_{W}L(W)+\\lambda\\|W\\|^2$.\n",
    "\n",
    "Здесь $L(W)$ является функцией ошибки многоклассовой классификации,\n",
    "\n",
    "$L(W)=- \\sum^N_{n=1}\\sum^K_{k=1} t_{kn} log(y_{kn}),$\n",
    "\n",
    "$t_{kn}$ -- бинарно закодированные метки классов, $K$ -- количество меток, $N$ -- количество объектов,\n",
    "\n",
    "а $\\lambda\\|W\\|^2$ является регуляризующим слагаемым, контролирующим суммарный вес параметров сети и предотвращающий эффект переобучения.\n",
    "\n",
    "Оптимизация параметров выполняется методом обратного распространения ошибки (backpropagation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполним загрузку основных модулей: ClassificationDataSet -- структура данных pybrain, buildNetwork -- инициализация нейронной сети, BackpropTrainer -- оптимизация параметров сети методом backpropagation, SoftmaxLayer -- функция softmax, соответствующая выходному слою сети, percentError -- функцию подсчета ошибки классификации (доля неправильных ответов). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pybrain.datasets import ClassificationDataSet # Структура данных pybrain\n",
    "from pybrain.tools.shortcuts import buildNetwork\n",
    "from pybrain.supervised.trainers import BackpropTrainer\n",
    "from pybrain.structure.modules import SoftmaxLayer\n",
    "from pybrain.utilities import percentError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Инициализируем основные параметры задачи: HIDDEN_NEURONS_NUM -- количество нейронов скрытого слоя, MAX_EPOCHS -- максимальное количество итераций алгоритма оптимизации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определение основных констант\n",
    "HIDDEN_NEURONS_NUM = 100 # Количество нейронов, содержащееся в скрытом слое сети\n",
    "MAX_EPOCHS = 100 # Максимальное число итераций алгоритма оптимизации параметров сети"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Инициализируем структуру данных ClassificationDataSet, используемую библиотекой pybrain. Для инициализации структура принимает два аргумента: количество признаков *np.shape(X)[1]* и количество различных меток классов *len(np.unique(y))*.\n",
    "\n",
    "Кроме того, произведем бинаризацию целевой переменной с помощью функции *_convertToOneOfMany( )* и разбиение данных на обучающую и контрольную части."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Конвертация данных в структуру ClassificationDataSet\n",
    "# Обучающая часть\n",
    "ds_train = ClassificationDataSet(np.shape(X)[1], nb_classes=len(np.unique(y_train)))\n",
    "# Первый аргумент -- количество признаков np.shape(X)[1], второй аргумент -- количество меток классов len(np.unique(y_train)))\n",
    "ds_train.setField('input', X_train) # Инициализация объектов\n",
    "ds_train.setField('target', y_train[:, np.newaxis]) # Инициализация ответов; np.newaxis создает вектор-столбец\n",
    "ds_train._convertToOneOfMany( ) # Бинаризация вектора ответов\n",
    "# Контрольная часть\n",
    "ds_test = ClassificationDataSet(np.shape(X)[1], nb_classes=len(np.unique(y_train)))\n",
    "ds_test.setField('input', X_test)\n",
    "ds_test.setField('target', y_test[:, np.newaxis])\n",
    "ds_test._convertToOneOfMany( )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Инициализируем двуслойную сеть и произведем оптимизацию ее параметров. Аргументами для инициализации являются:\n",
    "\n",
    "ds.indim -- количество нейронов на входном слое сети, совпадает с количеством признаков (в нашем случае 11),\n",
    "\n",
    "HIDDEN_NEURONS_NUM -- количество нейронов в скрытом слое сети,\n",
    "\n",
    "ds.outdim -- количество нейронов на выходном слое сети, совпадает с количеством различных меток классов (в нашем случае 3),\n",
    "\n",
    "SoftmaxLayer -- функция softmax, используемая на выходном слое для решения задачи многоклассовой классификации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(0) # Зафиксируем seed для получения воспроизводимого результата\n",
    "\n",
    "# Построение сети прямого распространения (Feedforward network)\n",
    "net = buildNetwork(ds_train.indim, HIDDEN_NEURONS_NUM, ds_train.outdim, outclass=SoftmaxLayer)\n",
    "# ds.indim -- количество нейронов входного слоя, равне количеству признаков\n",
    "# ds.outdim -- количество нейронов выходного слоя, равное количеству меток классов\n",
    "# SoftmaxLayer -- функция активации, пригодная для решения задачи многоклассовой классификации\n",
    "\n",
    "init_params = np.random.random((len(net.params))) # Инициализируем веса сети для получения воспроизводимого результата\n",
    "net._setParameters(init_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Выполним оптимизацию параметров сети. График ниже показывает сходимость функции ошибки на обучающей/контрольной части."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "random.seed(0)\n",
    "# Модуль настройки параметров pybrain использует модуль random; зафиксируем seed для получения воспроизводимого результата\n",
    "trainer = BackpropTrainer(net, dataset=ds_train) # Инициализируем модуль оптимизации\n",
    "err_train, err_val = trainer.trainUntilConvergence(maxEpochs=MAX_EPOCHS)\n",
    "line_train = plt.plot(err_train, 'b', err_val, 'r') # Построение графика\n",
    "xlab = plt.xlabel('Iterations')\n",
    "ylab = plt.ylabel('Error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассчитаем значение доли неправильных ответов на обучающей и контрольной выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on train:  51.29579982126899 %\n",
      "Error on test:  46.666666666666664 %\n"
     ]
    }
   ],
   "source": [
    "res_train = net.activateOnDataset(ds_train).argmax(axis=1) # Подсчет результата на обучающей выборке\n",
    "print ('Error on train: ', percentError(res_train, ds_train['target'].argmax(axis=1)), '%') # Подсчет ошибки\n",
    "res_test = net.activateOnDataset(ds_test).argmax(axis=1) # Подсчет результата на тестовой выборке\n",
    "print ('Error on test: ', percentError(res_test, ds_test['target'].argmax(axis=1)), '%') # Подсчет ошибки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание. Определение оптимального числа нейронов.\n",
    "В задании требуется исследовать зависимость ошибки на контрольной выборке в зависимости от числа нейронов в скрытом слое сети. Количество нейронов, по которому предполагается провести перебор, записано в векторе \n",
    "```\n",
    "hidden_neurons_num = [50, 100, 200, 500, 700, 1000]\n",
    "```\n",
    "\n",
    "1. Для фиксированного разбиения на обучающую и контрольную части подсчитайте долю неправильных ответов (ошибок) классификации на обучении/контроле в зависимости от количества нейронов в скрытом слое сети. Запишите результаты в массивы ```res_train_vec``` и ```res_test_vec```, соответственно. С помощью функции ```plot_classification_error``` постройте график зависимости ошибок на обучении/контроле от количества нейронов. Являются ли графики ошибок возрастающими/убывающими? При каком количестве нейронов достигается минимум ошибок классификации?\n",
    "\n",
    "2. С помощью функции ```write_answer_nn``` запишите в выходной файл число: количество нейронов в скрытом слое сети, для которого достигается минимум ошибки классификации на контрольной выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on train:  53.70866845397676 %\n",
      "Error on test:  52.916666666666664 %\n",
      "neurons:  50\n",
      "Error on train:  61.2153708668454 %\n",
      "Error on test:  57.5 %\n",
      "neurons:  100\n",
      "Error on train:  61.2153708668454 %\n",
      "Error on test:  57.5 %\n",
      "neurons:  200\n",
      "Error on train:  61.2153708668454 %\n",
      "Error on test:  57.5 %\n",
      "neurons:  500\n",
      "Error on train:  61.2153708668454 %\n",
      "Error on test:  57.5 %\n",
      "neurons:  700\n",
      "Error on train:  85.07596067917784 %\n",
      "Error on test:  89.58333333333333 %\n",
      "neurons:  1000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#random.seed(0) # Зафиксируем seed для получния воспроизводимого результата\n",
    "#np.random.seed(0)\n",
    "\n",
    "def plot_classification_error(hidden_neurons_num, res_train_vec, res_test_vec):\n",
    "# hidden_neurons_num -- массив размера h, содержащий количество нейронов, по которому предполагается провести перебор,\n",
    "#   hidden_neurons_num = [50, 100, 200, 500, 700, 1000];\n",
    "# res_train_vec -- массив размера h, содержащий значения доли неправильных ответов классификации на обучении;\n",
    "# res_train_vec -- массив размера h, содержащий значения доли неправильных ответов классификации на контроле\n",
    "    plt.figure()\n",
    "    plt.plot(hidden_neurons_num, res_train_vec)\n",
    "    plt.plot(hidden_neurons_num, res_test_vec, '-r')\n",
    "\n",
    "def write_answer_nn(optimal_neurons_num):\n",
    "    with open(\"nnets_answer1.txt\", \"w\") as fout:\n",
    "        fout.write(str(optimal_neurons_num))\n",
    "\n",
    "hidden_neurons_num = [50, 100, 200, 500, 700, 1000]\n",
    "res_train_vec = list()\n",
    "res_test_vec = list()\n",
    "\n",
    "for nnum in hidden_neurons_num:\n",
    "    # Put your code here\n",
    "    # Не забудьте про инициализацию весов командой np.random.random((len(net.params)))\n",
    "    net = buildNetwork(ds_train.indim, nnum, ds_train.outdim, outclass=SoftmaxLayer)\n",
    "    init_params = np.random.random((len(net.params)))\n",
    "    net._setParameters(init_params)\n",
    "    trainer = BackpropTrainer(net, dataset=ds_train) # Инициализируем модуль оптимизации\n",
    "    res_train = net.activateOnDataset(ds_train).argmax(axis=1) # Подсчет результата на обучающей выборке\n",
    "    print ('Error on train: ', percentError(res_train, ds_train['target'].argmax(axis=1)), '%') # Подсчет ошибки\n",
    "    res_test = net.activateOnDataset(ds_test).argmax(axis=1) # Подсчет результата на тестовой выборке\n",
    "    print ('Error on test: ', percentError(res_test, ds_test['target'].argmax(axis=1)), '%') # Подсчет ошибки\n",
    "    print(\"neurons: \", nnum)\n",
    "    res_train_vec.append(res_train); res_test_vec.append(res_test)\n",
    "    \n",
    "    \n",
    "# Постройте график зависимости ошибок на обучении и контроле в зависимости от количества нейронов\n",
    "plot_classification_error(hidden_neurons_num, res_train_vec, res_test_vec)          \n",
    "#  Запишите в файл количество нейронов, при котором достигается минимум ошибки на контроле"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.1077551563341753,\n",
       "  0.10852988350684069,\n",
       "  0.10632978058511597,\n",
       "  0.10730925677992169,\n",
       "  0.10734385575090595,\n",
       "  0.10703652777497272,\n",
       "  0.10766387867432681,\n",
       "  0.10744182117224181,\n",
       "  0.10604067897446072,\n",
       "  0.106091437265243,\n",
       "  0.10581745145157362,\n",
       "  0.10723999264081237,\n",
       "  0.1050013649285825,\n",
       "  0.10609746039199243,\n",
       "  0.1066591852838884,\n",
       "  0.10484324863976688,\n",
       "  0.10569868383733279,\n",
       "  0.10387563235682842,\n",
       "  0.10386482504777868,\n",
       "  0.1054914804879976,\n",
       "  0.10521536623966248,\n",
       "  0.1046524717079326,\n",
       "  0.10488180484943276,\n",
       "  0.10459847805284736,\n",
       "  0.10369142843359797,\n",
       "  0.10299462262242297,\n",
       "  0.10299757092002622,\n",
       "  0.10355965259325206,\n",
       "  0.1045607689918908,\n",
       "  0.10390277117839955,\n",
       "  0.1038226850930897,\n",
       "  0.1023654837369424,\n",
       "  0.10247200239494893,\n",
       "  0.10339631826529733,\n",
       "  0.10377146422726266,\n",
       "  0.10394885949482731,\n",
       "  0.1019252996023921,\n",
       "  0.10359094935246596,\n",
       "  0.10197003169891497,\n",
       "  0.10291194122554874,\n",
       "  0.10320679676836213,\n",
       "  0.10340584312201456,\n",
       "  0.10338947461395886,\n",
       "  0.10249684051806054,\n",
       "  0.10249547791409819,\n",
       "  0.10225090784369045,\n",
       "  0.10355167638584446,\n",
       "  0.10258991030290818,\n",
       "  0.10178018411237683,\n",
       "  0.10256541763908102,\n",
       "  0.10273367511955217,\n",
       "  0.10124199681452042,\n",
       "  0.10295561964130917,\n",
       "  0.10364822550300871,\n",
       "  0.10357069554811849,\n",
       "  0.10361726294247321,\n",
       "  0.10275077180659066,\n",
       "  0.10225726469126821,\n",
       "  0.10305664122025972,\n",
       "  0.10200936207028917,\n",
       "  0.10201596190122855,\n",
       "  0.10226228441427278,\n",
       "  0.101598933272861,\n",
       "  0.10344335688493929,\n",
       "  0.10337649202561072,\n",
       "  0.1025642028190657,\n",
       "  0.10267699948351075,\n",
       "  0.10183558335018589,\n",
       "  0.1025074784007063,\n",
       "  0.10289353187291363,\n",
       "  0.10157987670743475,\n",
       "  0.10198465654063628,\n",
       "  0.10240084233093728,\n",
       "  0.10121564350456393,\n",
       "  0.10263965595871045,\n",
       "  0.10177696677571163,\n",
       "  0.10167500663020228,\n",
       "  0.1025897005492728,\n",
       "  0.10246221887782146,\n",
       "  0.10144505268667452,\n",
       "  0.1013757395253663,\n",
       "  0.10146655398700749,\n",
       "  0.10177192315905577,\n",
       "  0.10170300810445038,\n",
       "  0.10100715872619845,\n",
       "  0.10156900351992469,\n",
       "  0.10216128000287038,\n",
       "  0.1017034091496891,\n",
       "  0.10224710364183338,\n",
       "  0.10188781441252165,\n",
       "  0.10196957745801262,\n",
       "  0.10145653743718104,\n",
       "  0.10192407601778519,\n",
       "  0.10089935906517437,\n",
       "  0.10154321324620036,\n",
       "  0.10154278921796568],\n",
       " [0.11412279151030506,\n",
       "  0.11392469807398088,\n",
       "  0.11259490427953806,\n",
       "  0.11268924415955732,\n",
       "  0.11291156243495244,\n",
       "  0.10986392557994565,\n",
       "  0.11150998731046763,\n",
       "  0.1121336084385235,\n",
       "  0.1103345104437751,\n",
       "  0.10999755253903273,\n",
       "  0.10757047369844386,\n",
       "  0.10736670458258378,\n",
       "  0.10974082229403442,\n",
       "  0.10692581235097452,\n",
       "  0.10765368425749028,\n",
       "  0.10872938140294415,\n",
       "  0.10810972807463656,\n",
       "  0.10706144530400337,\n",
       "  0.10928682783553033,\n",
       "  0.10840047268371696,\n",
       "  0.10831751269590022,\n",
       "  0.1080484572997828,\n",
       "  0.10876908006350909,\n",
       "  0.10651408202710252,\n",
       "  0.1068192632000881,\n",
       "  0.10902927636775601,\n",
       "  0.10664704554882146,\n",
       "  0.10663859835181402,\n",
       "  0.10798570245716917,\n",
       "  0.10694780763530974],\n",
       " [0.13270013212210108,\n",
       "  0.1303178302895873,\n",
       "  0.1259048732906497,\n",
       "  0.12340638267164677,\n",
       "  0.12441661292819496,\n",
       "  0.1275985238834638,\n",
       "  0.12403158223636056,\n",
       "  0.12463922345130678,\n",
       "  0.12181605998303241,\n",
       "  0.12670595527060308,\n",
       "  0.12000716646574933,\n",
       "  0.12251259164911062,\n",
       "  0.12379616544256236,\n",
       "  0.12138293326595012,\n",
       "  0.1225508397550828,\n",
       "  0.12082957872213698,\n",
       "  0.12085034785707645,\n",
       "  0.12167255247573389,\n",
       "  0.1186225334729905,\n",
       "  0.11786648852080371,\n",
       "  0.11946403350466754,\n",
       "  0.12150976055533519,\n",
       "  0.12216086736265312,\n",
       "  0.11695266313175669,\n",
       "  0.11767864773897072,\n",
       "  0.12163377501856606,\n",
       "  0.11854723448664344,\n",
       "  0.11901463504262007,\n",
       "  0.11801878904944908,\n",
       "  0.12080869079528803,\n",
       "  0.11971223869723117,\n",
       "  0.11984934806635396,\n",
       "  0.12216803957893217,\n",
       "  0.1195696044647195,\n",
       "  0.11773766824954283,\n",
       "  0.11839249247919924,\n",
       "  0.11929043865343152,\n",
       "  0.11748398924614907,\n",
       "  0.11956489087535871,\n",
       "  0.12150902724115341,\n",
       "  0.12010303376177545,\n",
       "  0.1171310273396149,\n",
       "  0.11962812888868321,\n",
       "  0.11751610726916766,\n",
       "  0.1150441609126493,\n",
       "  0.11484681871349918,\n",
       "  0.11707869600240339,\n",
       "  0.11568912462264994,\n",
       "  0.119947290095076,\n",
       "  0.11627208308874312,\n",
       "  0.11780828151416212,\n",
       "  0.11661057064774523,\n",
       "  0.11864332990787857,\n",
       "  0.11519714470276936,\n",
       "  0.11478746702750509,\n",
       "  0.11741957980435248,\n",
       "  0.11656414145836204,\n",
       "  0.11655317215613069,\n",
       "  0.11802445583165858,\n",
       "  0.11109564929004201,\n",
       "  0.11649688566077558,\n",
       "  0.11293870927650396,\n",
       "  0.117682044097043,\n",
       "  0.11391399092143602,\n",
       "  0.11151141953908413,\n",
       "  0.11285865535113863,\n",
       "  0.11534535550511715,\n",
       "  0.11466057240231935,\n",
       "  0.11522947621662077,\n",
       "  0.11473390682677154,\n",
       "  0.11343650788477307,\n",
       "  0.11582199246424325,\n",
       "  0.11466744695893859,\n",
       "  0.11450372160927282,\n",
       "  0.11455856348494499,\n",
       "  0.11327710137889928,\n",
       "  0.1105447248087499,\n",
       "  0.11096085923911173,\n",
       "  0.11224289405308178,\n",
       "  0.11186053801659632,\n",
       "  0.11270440700045477,\n",
       "  0.11525363498869427,\n",
       "  0.11089473819638834,\n",
       "  0.11349795522863142],\n",
       " [0.1812704876988995,\n",
       "  0.1775254409250494,\n",
       "  0.1808626716218234,\n",
       "  0.17050494622531848,\n",
       "  0.17073534124130346,\n",
       "  0.16393036764698485,\n",
       "  0.1518033047209304,\n",
       "  0.16665365122892456,\n",
       "  0.16723022265923426,\n",
       "  0.15361832837920483,\n",
       "  0.1591457407432494,\n",
       "  0.15459591449689172,\n",
       "  0.1570779672575743,\n",
       "  0.1572183121857788,\n",
       "  0.15658911638274578,\n",
       "  0.15290137693987751,\n",
       "  0.1536556875322554,\n",
       "  0.14687597571565436,\n",
       "  0.1516578407828772,\n",
       "  0.14652604475497907,\n",
       "  0.15195777522202428,\n",
       "  0.1571564977322513,\n",
       "  0.14928643119887652,\n",
       "  0.15628800139423263,\n",
       "  0.15017164285658113,\n",
       "  0.147500148857391,\n",
       "  0.149438097698613,\n",
       "  0.14974090240124244,\n",
       "  0.15157358021880332,\n",
       "  0.14305992861705047,\n",
       "  0.14761254752046343,\n",
       "  0.14859310904867512,\n",
       "  0.14636044803362133,\n",
       "  0.1498614410017527,\n",
       "  0.14788737726396217,\n",
       "  0.14818198448009579,\n",
       "  0.14674476821579688,\n",
       "  0.14896162597669432,\n",
       "  0.14555143293156297,\n",
       "  0.14733654388856557,\n",
       "  0.14715834291602836,\n",
       "  0.14281442103176104,\n",
       "  0.14813579324802673,\n",
       "  0.1426745918130745,\n",
       "  0.14673763785215446,\n",
       "  0.1469740214907852,\n",
       "  0.14371403073438954,\n",
       "  0.149482300625938,\n",
       "  0.15083960314374353,\n",
       "  0.14463685177056698,\n",
       "  0.1426901162404692,\n",
       "  0.1435301308577739,\n",
       "  0.14683833249711734,\n",
       "  0.1431796763530239,\n",
       "  0.14613730708963302,\n",
       "  0.14669256845058706,\n",
       "  0.135271408198905,\n",
       "  0.1450251650813479,\n",
       "  0.1453473950977208,\n",
       "  0.13812270860721915,\n",
       "  0.14416930120816318,\n",
       "  0.13574536325611297,\n",
       "  0.13936207760119212,\n",
       "  0.14348234190058545,\n",
       "  0.1345461171346799,\n",
       "  0.13959122871120183,\n",
       "  0.1362792381599328,\n",
       "  0.13661658618869704,\n",
       "  0.13799767264835702,\n",
       "  0.14264672136386558,\n",
       "  0.14405642799189486,\n",
       "  0.13741025914943425,\n",
       "  0.13929774347349258,\n",
       "  0.13569738849790874,\n",
       "  0.1403268945508467,\n",
       "  0.13492874803366012,\n",
       "  0.13715206855607465,\n",
       "  0.13629722008212744,\n",
       "  0.1356227389517097,\n",
       "  0.1334671642647109,\n",
       "  0.13442899576645187,\n",
       "  0.13788447737569318,\n",
       "  0.13381926591382517,\n",
       "  0.1328817689256147,\n",
       "  0.13165465716289268,\n",
       "  0.1319193505833521,\n",
       "  0.13602164530019217,\n",
       "  0.13387544131804,\n",
       "  0.13299817461608024,\n",
       "  0.1330174106211962,\n",
       "  0.12820572782903047,\n",
       "  0.1302620668883687,\n",
       "  0.13259889225394378,\n",
       "  0.13192014747906486,\n",
       "  0.12710557324980803],\n",
       " [0.19617958122642676,\n",
       "  0.1998956205581036,\n",
       "  0.19067362565242882,\n",
       "  0.19628911636422602,\n",
       "  0.1960700293662644,\n",
       "  0.18802583537265244,\n",
       "  0.18176698636546468,\n",
       "  0.17197917228169474,\n",
       "  0.17597635306656748,\n",
       "  0.16998481036869773,\n",
       "  0.17346564943378226,\n",
       "  0.1731485666051775,\n",
       "  0.17392967581151778,\n",
       "  0.1744763303616252,\n",
       "  0.17500102117292615,\n",
       "  0.1702770486081157,\n",
       "  0.1668304839105994,\n",
       "  0.16511324121416007,\n",
       "  0.16954196558132223,\n",
       "  0.16991979816005814,\n",
       "  0.17079979889087635,\n",
       "  0.1565202961674893,\n",
       "  0.16460165133571858,\n",
       "  0.16096018376307886,\n",
       "  0.1702283209083292,\n",
       "  0.17336911028971877,\n",
       "  0.16755546447811615,\n",
       "  0.16582329296953288,\n",
       "  0.1672943701698074,\n",
       "  0.16302451415340558,\n",
       "  0.17030383461461174,\n",
       "  0.17083867773065645,\n",
       "  0.16457086732970608,\n",
       "  0.16759043230134804,\n",
       "  0.17025479371252283,\n",
       "  0.17121897533919359,\n",
       "  0.17380525462332744,\n",
       "  0.1641959108966042,\n",
       "  0.15928051681118746,\n",
       "  0.17667351369580456,\n",
       "  0.1636338772034612,\n",
       "  0.17030504748598235,\n",
       "  0.16113411130199753,\n",
       "  0.16383966908334927,\n",
       "  0.16132539882777724,\n",
       "  0.16392849379885394,\n",
       "  0.15689963022674902,\n",
       "  0.16021817468915897,\n",
       "  0.15739728049295099,\n",
       "  0.15789158874870649,\n",
       "  0.16345316353702202,\n",
       "  0.15865782524041838,\n",
       "  0.16721531010661322,\n",
       "  0.16180421049897406,\n",
       "  0.16385958103804846,\n",
       "  0.16224667066483747,\n",
       "  0.15804152091450077,\n",
       "  0.15885301283550585,\n",
       "  0.15978524684475637,\n",
       "  0.14999701015848188,\n",
       "  0.15614502721701798,\n",
       "  0.16095175010294738,\n",
       "  0.15266880294626844,\n",
       "  0.15199444731680717,\n",
       "  0.15993624359534708,\n",
       "  0.1570214047413784,\n",
       "  0.15476744926446656,\n",
       "  0.15010458816976813,\n",
       "  0.15689188639291984,\n",
       "  0.1569671159306435,\n",
       "  0.151589213239366,\n",
       "  0.15676228729687897,\n",
       "  0.15351875763385783,\n",
       "  0.15339268310040535,\n",
       "  0.1532902977068249,\n",
       "  0.15850375085049356,\n",
       "  0.1524550380694298,\n",
       "  0.1546174474743308,\n",
       "  0.15200894673146517,\n",
       "  0.1501898252593616,\n",
       "  0.1544463123251346,\n",
       "  0.15408125380937315,\n",
       "  0.14389143100280555,\n",
       "  0.1546993655336767,\n",
       "  0.14729274173951964,\n",
       "  0.1493477981810075,\n",
       "  0.14945420696227532,\n",
       "  0.14356122471536045,\n",
       "  0.14737658368111048,\n",
       "  0.14661885900653346,\n",
       "  0.14898593167207239,\n",
       "  0.14721446004541613,\n",
       "  0.1478430670581854],\n",
       " [0.20466429876676578,\n",
       "  0.20396605441838755,\n",
       "  0.2024180260177945,\n",
       "  0.20347454604728699,\n",
       "  0.19388856393743958,\n",
       "  0.19648704005082157,\n",
       "  0.18094298950208204,\n",
       "  0.18132863912765615,\n",
       "  0.18786472342657934,\n",
       "  0.18315971147439514,\n",
       "  0.18517711571602272,\n",
       "  0.18651434238185768,\n",
       "  0.18401159913228485,\n",
       "  0.176695686292459,\n",
       "  0.18053199384365204,\n",
       "  0.18259369489382374,\n",
       "  0.18692646316126313,\n",
       "  0.1779704185073459,\n",
       "  0.19197907009804197,\n",
       "  0.1734364283331115,\n",
       "  0.1887762528637459,\n",
       "  0.17821825791421034,\n",
       "  0.18376721741280766,\n",
       "  0.1871599077631872,\n",
       "  0.1738893055811266,\n",
       "  0.17960567745004635,\n",
       "  0.1777017743522378,\n",
       "  0.17858561026725125,\n",
       "  0.1681738950792843,\n",
       "  0.17542550262707832,\n",
       "  0.16815750718294994,\n",
       "  0.18079985764493187,\n",
       "  0.17988283419053971,\n",
       "  0.18166717667765842,\n",
       "  0.16840472116368563,\n",
       "  0.1741204677466728,\n",
       "  0.17017019759883784,\n",
       "  0.1808802283752945,\n",
       "  0.185720242007072,\n",
       "  0.16900207486513213,\n",
       "  0.1813802297584945,\n",
       "  0.16892428174495414,\n",
       "  0.1774163098124187,\n",
       "  0.1781063285932649,\n",
       "  0.17795650834700516,\n",
       "  0.17433791472161023,\n",
       "  0.16694502680775433,\n",
       "  0.17628836301445913,\n",
       "  0.17364405868236624,\n",
       "  0.17814355971067344,\n",
       "  0.1731247970111765,\n",
       "  0.16714250526670935,\n",
       "  0.1759989111697238,\n",
       "  0.16829308147622624,\n",
       "  0.17795300803171277,\n",
       "  0.1786663194875086,\n",
       "  0.17382224761387985,\n",
       "  0.1724294430656078,\n",
       "  0.1666620882937714,\n",
       "  0.17406500967757968,\n",
       "  0.16508599056926276,\n",
       "  0.17192336976742414,\n",
       "  0.16842644831461925,\n",
       "  0.17072141156330375,\n",
       "  0.16708081295393173,\n",
       "  0.1663688778930215,\n",
       "  0.17344203662376292,\n",
       "  0.16870874980925907,\n",
       "  0.17895616786825122,\n",
       "  0.17298878230046352,\n",
       "  0.1651867440113272,\n",
       "  0.16707594894875735,\n",
       "  0.16698741607229295,\n",
       "  0.16614484045715863,\n",
       "  0.16691285094406433,\n",
       "  0.1687900908058336,\n",
       "  0.17537515784134364,\n",
       "  0.16527405955453345,\n",
       "  0.16639286677327714,\n",
       "  0.163339811013577,\n",
       "  0.16699698737071522,\n",
       "  0.1615619495998362,\n",
       "  0.16852787339834618]]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_train_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
