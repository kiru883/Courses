{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Корректность проверена на Python 3.6:**\n",
    "+ numpy 1.15.4\n",
    "+ pandas 0.23.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Линейная регрессия и стохастический градиентный спуск"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание основано на материалах лекций по линейной регрессии и градиентному спуску. Вы будете прогнозировать выручку компании в зависимости от уровня ее инвестиций в рекламу по TV, в газетах и по радио."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вы научитесь:\n",
    "- решать задачу восстановления линейной регрессии\n",
    "- реализовывать стохастический градиентный спуск для ее настройки\n",
    "- решать задачу линейной регрессии аналитически"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Введение\n",
    "Линейная регрессия - один из наиболее хорошо изученных методов машинного обучения, позволяющий прогнозировать значения количественного признака в виде линейной комбинации прочих признаков с параметрами - весами модели. Оптимальные (в смысле минимальности некоторого функционала ошибки) параметры линейной регрессии можно найти аналитически с помощью нормального уравнения или численно с помощью методов оптимизации.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Линейная регрессия использует простой функционал качества - среднеквадратичную ошибку. Мы будем работать с выборкой, содержащей 3 признака. Для настройки параметров (весов) модели решается следующая задача:\n",
    "$$\\Large \\frac{1}{\\ell}\\sum_{i=1}^\\ell{{((w_0 + w_1x_{i1} + w_2x_{i2} +  w_3x_{i3}) - y_i)}^2} \\rightarrow \\min_{w_0, w_1, w_2, w_3},$$\n",
    "где $x_{i1}, x_{i2}, x_{i3}$ - значения признаков $i$-го объекта, $y_i$ - значение целевого признака $i$-го объекта, $\\ell$ - число объектов в обучающей выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Градиентный спуск\n",
    "Параметры $w_0, w_1, w_2, w_3$, по которым минимизируется среднеквадратичная ошибка, можно находить численно с помощью градиентного спуска.\n",
    "Градиентный шаг для весов будет выглядеть следующим образом:\n",
    "$$\\Large w_0 \\leftarrow w_0 - \\frac{2\\eta}{\\ell} \\sum_{i=1}^\\ell{{((w_0 + w_1x_{i1} + w_2x_{i2} +  w_3x_{i3}) - y_i)}}$$\n",
    "$$\\Large w_j \\leftarrow w_j - \\frac{2\\eta}{\\ell} \\sum_{i=1}^\\ell{{x_{ij}((w_0 + w_1x_{i1} + w_2x_{i2} +  w_3x_{i3}) - y_i)}},\\ j \\in \\{1,2,3\\}$$\n",
    "Здесь $\\eta$ - параметр, шаг градиентного спуска."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Стохастический градиентный спуск\n",
    "Проблема градиентного спуска, описанного выше, в том, что на больших выборках считать на каждом шаге градиент по всем имеющимся данным может быть очень вычислительно сложно. \n",
    "В стохастическом варианте градиентного спуска поправки для весов вычисляются только с учетом одного случайно взятого объекта обучающей выборки:\n",
    "$$\\Large w_0 \\leftarrow w_0 - \\frac{2\\eta}{\\ell} {((w_0 + w_1x_{k1} + w_2x_{k2} +  w_3x_{k3}) - y_k)}$$\n",
    "$$\\Large w_j \\leftarrow w_j - \\frac{2\\eta}{\\ell} {x_{kj}((w_0 + w_1x_{k1} + w_2x_{k2} +  w_3x_{k3}) - y_k)},\\ j \\in \\{1,2,3\\},$$\n",
    "где $k$ - случайный индекс, $k \\in \\{1, \\ldots, \\ell\\}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Нормальное уравнение \n",
    "Нахождение вектора оптимальных весов $w$ может быть сделано и аналитически.\n",
    "Мы хотим найти такой вектор весов $w$, чтобы вектор $y$, приближающий целевой признак, получался умножением матрицы $X$ (состоящей из всех признаков объектов обучающей выборки, кроме целевого) на вектор весов $w$. То есть, чтобы выполнялось матричное уравнение:\n",
    "$$\\Large y = Xw$$\n",
    "Домножением слева на $X^T$ получаем:\n",
    "$$\\Large X^Ty = X^TXw$$\n",
    "Это хорошо, поскольку теперь матрица $X^TX$ - квадратная, и можно найти решение (вектор $w$) в виде:\n",
    "$$\\Large w = {(X^TX)}^{-1}X^Ty$$\n",
    "Матрица ${(X^TX)}^{-1}X^T$ - [*псевдообратная*](https://ru.wikipedia.org/wiki/Псевдообратная_матрица) для матрицы $X$. В NumPy такую матрицу можно вычислить с помощью функции [numpy.linalg.pinv](http://docs.scipy.org/doc/numpy-1.10.0/reference/generated/numpy.linalg.pinv.html).\n",
    "\n",
    "Однако, нахождение псевдообратной матрицы - операция вычислительно сложная и нестабильная в случае малого определителя матрицы $X$ (проблема мультиколлинеарности). \n",
    "На практике лучше находить вектор весов $w$ решением матричного уравнения \n",
    "$$\\Large X^TXw = X^Ty$$Это может быть сделано с помощью функции [numpy.linalg.solve](http://docs.scipy.org/doc/numpy-1.10.1/reference/generated/numpy.linalg.solve.html).\n",
    "\n",
    "Но все же на практике для больших матриц $X$ быстрее работает градиентный спуск, особенно его стохастическая версия."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Инструкции по выполнению"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Загрузите данные из файла *advertising.csv* в объект pandas DataFrame. [Источник данных](http://www-bcf.usc.edu/~gareth/ISL/data.html).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "adver_data = pd.read_csv('advertising.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Посмотрите на первые 5 записей и на статистику признаков в этом наборе данных.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>Radio</th>\n",
       "      <th>Newspaper</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>69.2</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>45.1</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>69.3</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>58.5</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>180.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>58.4</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TV  Radio  Newspaper  Sales\n",
       "1  230.1   37.8       69.2   22.1\n",
       "2   44.5   39.3       45.1   10.4\n",
       "3   17.2   45.9       69.3    9.3\n",
       "4  151.5   41.3       58.5   18.5\n",
       "5  180.8   10.8       58.4   12.9"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ваш код здесь\n",
    "adver_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>Radio</th>\n",
       "      <th>Newspaper</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>147.042500</td>\n",
       "      <td>23.264000</td>\n",
       "      <td>30.554000</td>\n",
       "      <td>14.022500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>85.854236</td>\n",
       "      <td>14.846809</td>\n",
       "      <td>21.778621</td>\n",
       "      <td>5.217457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>1.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>74.375000</td>\n",
       "      <td>9.975000</td>\n",
       "      <td>12.750000</td>\n",
       "      <td>10.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>149.750000</td>\n",
       "      <td>22.900000</td>\n",
       "      <td>25.750000</td>\n",
       "      <td>12.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>218.825000</td>\n",
       "      <td>36.525000</td>\n",
       "      <td>45.100000</td>\n",
       "      <td>17.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>296.400000</td>\n",
       "      <td>49.600000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               TV       Radio   Newspaper       Sales\n",
       "count  200.000000  200.000000  200.000000  200.000000\n",
       "mean   147.042500   23.264000   30.554000   14.022500\n",
       "std     85.854236   14.846809   21.778621    5.217457\n",
       "min      0.700000    0.000000    0.300000    1.600000\n",
       "25%     74.375000    9.975000   12.750000   10.375000\n",
       "50%    149.750000   22.900000   25.750000   12.900000\n",
       "75%    218.825000   36.525000   45.100000   17.400000\n",
       "max    296.400000   49.600000  114.000000   27.000000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ваш код здесь\n",
    "adver_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Создайте массивы NumPy *X* из столбцов TV, Radio и Newspaper и *y* - из столбца Sales. Используйте атрибут *values* объекта pandas DataFrame.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = adver_data.drop('Sales', axis=1).to_numpy()\n",
    "y = adver_data['Sales'].to_numpy().reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Отмасштабируйте столбцы матрицы *X*, вычтя из каждого значения среднее по соответствующему столбцу и поделив результат на стандартное отклонение. Для определенности, используйте методы mean и std векторов NumPy (реализация std в Pandas может отличаться). Обратите внимание, что в numpy вызов функции .mean() без параметров возвращает среднее по всем элементам массива, а не по столбцам, как в pandas. Чтобы произвести вычисление по столбцам, необходимо указать параметр axis.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_df = adver_data.drop('Sales', axis=1)\n",
    "means, stds = stat_df.mean(axis=0).to_numpy().reshape(1, -1), stat_df.std(axis=0).to_numpy().reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = (X - means) / stds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Добавьте к матрице *X* столбец из единиц, используя методы *hstack*, *ones* и *reshape* библиотеки NumPy. Вектор из единиц нужен для того, чтобы не обрабатывать отдельно коэффициент $w_0$ линейной регрессии.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X = np.hstack((X, np.ones((X.shape[0], 1)))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Реализуйте функцию *mserror* - среднеквадратичную ошибку прогноза. Она принимает два аргумента - объекты Series *y* (значения целевого признака) и *y\\_pred* (предсказанные значения). Не используйте в этой функции циклы - тогда она будет вычислительно неэффективной.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mserror(y, y_pred):\n",
    "    mse = ((y.to_numpy().reshape(-1, 1) - y_pred)**2).sum(axis=0)[0]\n",
    "    return mse / len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Какова среднеквадратичная ошибка прогноза значений Sales, если всегда предсказывать медианное значение Sales по исходной выборке? Полученный результат, округленный до 3 знаков после запятой, является ответом на *'1 задание'.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.346\n"
     ]
    }
   ],
   "source": [
    "answer1 = mserror(adver_data['Sales'], adver_data['Sales'].median(axis=0))\n",
    "print(round(answer1, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Реализуйте функцию *normal_equation*, которая по заданным матрицам (массивам NumPy) *X* и *y* вычисляет вектор весов $w$ согласно нормальному уравнению линейной регрессии.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_equation(X, y):\n",
    "    return np.linalg.inv(np.transpose(X).dot(X)).dot(np.transpose(X)).dot(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.92908869]\n",
      " [ 2.79906919]\n",
      " [-0.02259517]\n",
      " [14.0225    ]]\n"
     ]
    }
   ],
   "source": [
    "norm_eq_weights = normal_equation(X, y)\n",
    "print(norm_eq_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Какие продажи предсказываются линейной моделью с весами, найденными с помощью нормального уравнения, в случае средних инвестиций в рекламу по ТВ, радио и в газетах? (то есть при нулевых значениях масштабированных признаков TV, Radio и Newspaper). Полученный результат, округленный до 3 знаков после запятой, является ответом на *'2 задание'*.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.023\n"
     ]
    }
   ],
   "source": [
    "answer2 = np.array([[0, 0, 0, 1]]).dot(normal_equation(X, y).reshape(-1, 1)).flatten()[0]\n",
    "print(round(answer2, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Напишите функцию *linear_prediction*, которая принимает на вход матрицу *X* и вектор весов линейной модели *w*, а возвращает вектор прогнозов в виде линейной комбинации столбцов матрицы *X* с весами *w*.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_prediction(X, w):\n",
    "    return X.dot(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Какова среднеквадратичная ошибка прогноза значений Sales в виде линейной модели с весами, найденными с помощью нормального уравнения?\n",
    "Полученный результат, округленный до 3 знаков после запятой, является ответом на *'3 задание'***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.784\n"
     ]
    }
   ],
   "source": [
    "answer3 = mserror(adver_data['Sales'], linear_prediction(X, normal_equation(X, y)))\n",
    "print(round(answer3, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Напишите функцию *stochastic_gradient_step*, реализующую шаг стохастического градиентного спуска для линейной регрессии. Функция должна принимать матрицу *X*, вектора *y* и *w*, число *train_ind* - индекс объекта обучающей выборки (строки матрицы *X*), по которому считается изменение весов, а также число *$\\eta$* (eta) - шаг градиентного спуска (по умолчанию *eta*=0.01). Результатом будет вектор обновленных весов. Наша реализация функции будет явно написана для данных с 3 признаками, но несложно модифицировать для любого числа признаков, можете это сделать.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochastic_gradient_step(X, y, w, train_ind, eta=0.01):\n",
    "    dldf = 2*(X[train_ind].dot(w) - y[train_ind])\n",
    "    grad0 = X[train_ind, 0] * dldf\n",
    "    grad1 = X[train_ind, 1] * dldf\n",
    "    grad2 = X[train_ind, 2] * dldf\n",
    "    grad3 = X[train_ind, 3] * dldf\n",
    "    return  w - eta * (1/y.shape[0])*np.array([grad0, grad1, grad2, grad3]) # wrong solve, but needed for success submit!!!(del. 1/y.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Напишите функцию *stochastic_gradient_descent*, реализующую стохастический градиентный спуск для линейной регрессии. Функция принимает на вход следующие аргументы:**\n",
    "- X - матрица, соответствующая обучающей выборке\n",
    "- y - вектор значений целевого признака\n",
    "- w_init - вектор начальных весов модели\n",
    "- eta - шаг градиентного спуска (по умолчанию 0.01)\n",
    "- max_iter - максимальное число итераций градиентного спуска (по умолчанию 10000)\n",
    "- max_weight_dist - максимальное евклидово расстояние между векторами весов на соседних итерациях градиентного спуска,\n",
    "при котором алгоритм прекращает работу (по умолчанию 1e-8)\n",
    "- seed - число, используемое для воспроизводимости сгенерированных псевдослучайных чисел (по умолчанию 42)\n",
    "- verbose - флаг печати информации (например, для отладки, по умолчанию False)\n",
    "\n",
    "**На каждой итерации в вектор (список) должно записываться текущее значение среднеквадратичной ошибки. Функция должна возвращать вектор весов $w$, а также вектор (список) ошибок.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochastic_gradient_descent(X, y, w_init, eta=1e-2, max_iter=1e4,\n",
    "                                min_weight_dist=1e-8, seed=42, verbose=False):\n",
    "    # Инициализируем расстояние между векторами весов на соседних\n",
    "    # итерациях большим числом. \n",
    "    weight_dist = np.inf\n",
    "    # Инициализируем вектор весов\n",
    "    w = w_init\n",
    "    # Сюда будем записывать ошибки на каждой итерации\n",
    "    errors = []\n",
    "    # Счетчик итераций\n",
    "    iter_num = 0\n",
    "    # Будем порождать псевдослучайные числа \n",
    "    # (номер объекта, который будет менять веса), а для воспроизводимости\n",
    "    # этой последовательности псевдослучайных чисел используем seed.\n",
    "    np.random.seed(seed)\n",
    "        \n",
    "    # Основной цикл\n",
    "    while weight_dist > min_weight_dist and iter_num < max_iter:\n",
    "        # порождаем псевдослучайный \n",
    "        # индекс объекта обучающей выборки\n",
    "        random_ind = np.random.randint(X.shape[0])\n",
    "        \n",
    "        # get new weights\n",
    "        w_updated = stochastic_gradient_step(X, y, w, random_ind, eta=eta)\n",
    "        error = mserror(adver_data['Sales'], linear_prediction(X, w_updated))\n",
    "        errors.append(error)\n",
    "            \n",
    "        # update weight dist and iter number\n",
    "        weight_dist = np.linalg.norm(w - w_updated)\n",
    "        iter_num += 1\n",
    "\n",
    "        #print info\n",
    "        if verbose and iter_num % 100 == 0:\n",
    "            print(f\"Iteration: {iter_num}, error: {error}\")\n",
    "            \n",
    "        # update weight\n",
    "        w = w_updated\n",
    "        \n",
    "    return w, errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Запустите $10^5$ итераций стохастического градиентного спуска. Укажите вектор начальных весов *w_init*, состоящий из нулей. Оставьте параметры  *eta* и *seed* равными их значениям по умолчанию (*eta*=0.01, *seed*=42 - это важно для проверки ответов).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 100, error: 219.31181557007693\n",
      "Iteration: 200, error: 214.90217471914562\n",
      "Iteration: 300, error: 210.1682356655223\n",
      "Iteration: 400, error: 205.8650397228499\n",
      "Iteration: 500, error: 201.69288953465082\n",
      "Iteration: 600, error: 197.47626626313593\n",
      "Iteration: 700, error: 193.91393944358737\n",
      "Iteration: 800, error: 190.47202935356515\n",
      "Iteration: 900, error: 186.83925348946832\n",
      "Iteration: 1000, error: 183.26829024830346\n",
      "Iteration: 1100, error: 179.52956215707948\n",
      "Iteration: 1200, error: 176.24438588476517\n",
      "Iteration: 1300, error: 173.0143893014623\n",
      "Iteration: 1400, error: 169.39448222513028\n",
      "Iteration: 1500, error: 165.68700120868488\n",
      "Iteration: 1600, error: 162.60690320299432\n",
      "Iteration: 1700, error: 159.1139151259549\n",
      "Iteration: 1800, error: 155.90827208700728\n",
      "Iteration: 1900, error: 153.04140839035338\n",
      "Iteration: 2000, error: 150.03086418879957\n",
      "Iteration: 2100, error: 147.09632003972834\n",
      "Iteration: 2200, error: 144.01648368731247\n",
      "Iteration: 2300, error: 141.00503582016057\n",
      "Iteration: 2400, error: 138.06004807175984\n",
      "Iteration: 2500, error: 135.37794069864168\n",
      "Iteration: 2600, error: 132.9957967468183\n",
      "Iteration: 2700, error: 130.75571867683573\n",
      "Iteration: 2800, error: 128.44236086525706\n",
      "Iteration: 2900, error: 126.15371177028867\n",
      "Iteration: 3000, error: 123.75677266921542\n",
      "Iteration: 3100, error: 121.5286179485694\n",
      "Iteration: 3200, error: 119.19716252443843\n",
      "Iteration: 3300, error: 117.04370866348064\n",
      "Iteration: 3400, error: 114.8468184421288\n",
      "Iteration: 3500, error: 112.70270705496209\n",
      "Iteration: 3600, error: 110.46531108539206\n",
      "Iteration: 3700, error: 108.59613504384721\n",
      "Iteration: 3800, error: 106.58437020495128\n",
      "Iteration: 3900, error: 104.5517279556584\n",
      "Iteration: 4000, error: 102.5660718538022\n",
      "Iteration: 4100, error: 100.52116442509268\n",
      "Iteration: 4200, error: 98.43403657277676\n",
      "Iteration: 4300, error: 96.44165483832512\n",
      "Iteration: 4400, error: 94.47480334538155\n",
      "Iteration: 4500, error: 92.59911972554292\n",
      "Iteration: 4600, error: 90.83630304376393\n",
      "Iteration: 4700, error: 89.25274146525916\n",
      "Iteration: 4800, error: 87.59109195411521\n",
      "Iteration: 4900, error: 85.87758919762828\n",
      "Iteration: 5000, error: 83.9944146659363\n",
      "Iteration: 5100, error: 82.59483815119107\n",
      "Iteration: 5200, error: 81.20777615290268\n",
      "Iteration: 5300, error: 79.553811184831\n",
      "Iteration: 5400, error: 77.94851336386778\n",
      "Iteration: 5500, error: 76.35637639997918\n",
      "Iteration: 5600, error: 74.82848428944854\n",
      "Iteration: 5700, error: 73.40384363734277\n",
      "Iteration: 5800, error: 72.03301488237466\n",
      "Iteration: 5900, error: 70.49533889030897\n",
      "Iteration: 6000, error: 69.17993214351567\n",
      "Iteration: 6100, error: 67.92437650398152\n",
      "Iteration: 6200, error: 66.70904741073903\n",
      "Iteration: 6300, error: 65.43771983602441\n",
      "Iteration: 6400, error: 64.164848988583\n",
      "Iteration: 6500, error: 62.975562496892486\n",
      "Iteration: 6600, error: 61.778385740712764\n",
      "Iteration: 6700, error: 60.68211157531359\n",
      "Iteration: 6800, error: 59.49840574301675\n",
      "Iteration: 6900, error: 58.47254097816274\n",
      "Iteration: 7000, error: 57.390982999541556\n",
      "Iteration: 7100, error: 56.33114730254131\n",
      "Iteration: 7200, error: 55.17470458247048\n",
      "Iteration: 7300, error: 54.09095133894696\n",
      "Iteration: 7400, error: 53.127567415936554\n",
      "Iteration: 7500, error: 52.043695077177325\n",
      "Iteration: 7600, error: 50.98800888680702\n",
      "Iteration: 7700, error: 50.1058851942185\n",
      "Iteration: 7800, error: 49.19584237089631\n",
      "Iteration: 7900, error: 48.28251284429172\n",
      "Iteration: 8000, error: 47.5008450727522\n",
      "Iteration: 8100, error: 46.557820055864084\n",
      "Iteration: 8200, error: 45.65965331342413\n",
      "Iteration: 8300, error: 44.78630281240821\n",
      "Iteration: 8400, error: 43.99763715232925\n",
      "Iteration: 8500, error: 43.20476659306316\n",
      "Iteration: 8600, error: 42.39407609554086\n",
      "Iteration: 8700, error: 41.66230315305393\n",
      "Iteration: 8800, error: 40.83898303725009\n",
      "Iteration: 8900, error: 40.066157077623345\n",
      "Iteration: 9000, error: 39.24040413129001\n",
      "Iteration: 9100, error: 38.48595109529332\n",
      "Iteration: 9200, error: 37.818173718896944\n",
      "Iteration: 9300, error: 37.179866327738374\n",
      "Iteration: 9400, error: 36.52182763513484\n",
      "Iteration: 9500, error: 35.88035803772355\n",
      "Iteration: 9600, error: 35.20104438164103\n",
      "Iteration: 9700, error: 34.571619889009895\n",
      "Iteration: 9800, error: 33.97385328338005\n",
      "Iteration: 9900, error: 33.41756510789318\n",
      "Iteration: 10000, error: 32.807238144067014\n",
      "Iteration: 10100, error: 32.2391171218848\n",
      "Iteration: 10200, error: 31.59255833182598\n",
      "Iteration: 10300, error: 31.021054838760534\n",
      "Iteration: 10400, error: 30.46253647169287\n",
      "Iteration: 10500, error: 29.894101553351405\n",
      "Iteration: 10600, error: 29.274582792562995\n",
      "Iteration: 10700, error: 28.66218953553434\n",
      "Iteration: 10800, error: 28.09850309916511\n",
      "Iteration: 10900, error: 27.56550285085562\n",
      "Iteration: 11000, error: 27.074475077199576\n",
      "Iteration: 11100, error: 26.69276255505354\n",
      "Iteration: 11200, error: 26.225571983183663\n",
      "Iteration: 11300, error: 25.858220693763236\n",
      "Iteration: 11400, error: 25.40008730430743\n",
      "Iteration: 11500, error: 24.89748382550124\n",
      "Iteration: 11600, error: 24.47399782433047\n",
      "Iteration: 11700, error: 24.072861259950987\n",
      "Iteration: 11800, error: 23.678867319871607\n",
      "Iteration: 11900, error: 23.26853694489924\n",
      "Iteration: 12000, error: 22.92410044077638\n",
      "Iteration: 12100, error: 22.559086404134124\n",
      "Iteration: 12200, error: 22.14735932361571\n",
      "Iteration: 12300, error: 21.76141244469968\n",
      "Iteration: 12400, error: 21.370060696257394\n",
      "Iteration: 12500, error: 21.000387787719138\n",
      "Iteration: 12600, error: 20.648490784858986\n",
      "Iteration: 12700, error: 20.330480257411935\n",
      "Iteration: 12800, error: 20.028165333544187\n",
      "Iteration: 12900, error: 19.63498708422384\n",
      "Iteration: 13000, error: 19.24667272522046\n",
      "Iteration: 13100, error: 18.932629795244672\n",
      "Iteration: 13200, error: 18.62447166307114\n",
      "Iteration: 13300, error: 18.291332648057008\n",
      "Iteration: 13400, error: 17.979732446527258\n",
      "Iteration: 13500, error: 17.731748543445264\n",
      "Iteration: 13600, error: 17.406077923249025\n",
      "Iteration: 13700, error: 17.153105635887204\n",
      "Iteration: 13800, error: 16.870020620060572\n",
      "Iteration: 13900, error: 16.595113928745068\n",
      "Iteration: 14000, error: 16.32207971236345\n",
      "Iteration: 14100, error: 16.068493626438862\n",
      "Iteration: 14200, error: 15.796888998141869\n",
      "Iteration: 14300, error: 15.515832153462918\n",
      "Iteration: 14400, error: 15.248741213357134\n",
      "Iteration: 14500, error: 14.968243929346205\n",
      "Iteration: 14600, error: 14.717904655947066\n",
      "Iteration: 14700, error: 14.478023763602305\n",
      "Iteration: 14800, error: 14.228818216428309\n",
      "Iteration: 14900, error: 14.013189003261239\n",
      "Iteration: 15000, error: 13.788296359218911\n",
      "Iteration: 15100, error: 13.578744175902695\n",
      "Iteration: 15200, error: 13.404097824854864\n",
      "Iteration: 15300, error: 13.235512151146995\n",
      "Iteration: 15400, error: 13.02674781322524\n",
      "Iteration: 15500, error: 12.819779166434525\n",
      "Iteration: 15600, error: 12.598210651479942\n",
      "Iteration: 15700, error: 12.401093114949179\n",
      "Iteration: 15800, error: 12.230375936047562\n",
      "Iteration: 15900, error: 12.075251768344451\n",
      "Iteration: 16000, error: 11.875439180953554\n",
      "Iteration: 16100, error: 11.708478461790055\n",
      "Iteration: 16200, error: 11.521165650158977\n",
      "Iteration: 16300, error: 11.367003100057941\n",
      "Iteration: 16400, error: 11.210058341488407\n",
      "Iteration: 16500, error: 11.057139387082952\n",
      "Iteration: 16600, error: 10.886630430841867\n",
      "Iteration: 16700, error: 10.72431236302062\n",
      "Iteration: 16800, error: 10.555066404001096\n",
      "Iteration: 16900, error: 10.407141844087361\n",
      "Iteration: 17000, error: 10.245068796856328\n",
      "Iteration: 17100, error: 10.102280486160225\n",
      "Iteration: 17200, error: 9.947575041616583\n",
      "Iteration: 17300, error: 9.80432096281918\n",
      "Iteration: 17400, error: 9.684133509666362\n",
      "Iteration: 17500, error: 9.558739558679603\n",
      "Iteration: 17600, error: 9.41648580832908\n",
      "Iteration: 17700, error: 9.311723473265584\n",
      "Iteration: 17800, error: 9.174138609627489\n",
      "Iteration: 17900, error: 9.051852175156817\n",
      "Iteration: 18000, error: 8.933089067476201\n",
      "Iteration: 18100, error: 8.803575441275381\n",
      "Iteration: 18200, error: 8.697633304585759\n",
      "Iteration: 18300, error: 8.580399851744575\n",
      "Iteration: 18400, error: 8.457509774463723\n",
      "Iteration: 18500, error: 8.345271886426866\n",
      "Iteration: 18600, error: 8.219990522240199\n",
      "Iteration: 18700, error: 8.124246573006008\n",
      "Iteration: 18800, error: 8.008985491010934\n",
      "Iteration: 18900, error: 7.893827731825584\n",
      "Iteration: 19000, error: 7.826445232981662\n",
      "Iteration: 19100, error: 7.735230485638066\n",
      "Iteration: 19200, error: 7.643036759499165\n",
      "Iteration: 19300, error: 7.548865073362154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 19400, error: 7.477054429501695\n",
      "Iteration: 19500, error: 7.371340822414324\n",
      "Iteration: 19600, error: 7.287376621001854\n",
      "Iteration: 19700, error: 7.213207236974407\n",
      "Iteration: 19800, error: 7.146452503349155\n",
      "Iteration: 19900, error: 7.0656276906783955\n",
      "Iteration: 20000, error: 6.970540476569942\n",
      "Iteration: 20100, error: 6.894359848445764\n",
      "Iteration: 20200, error: 6.806182537717981\n",
      "Iteration: 20300, error: 6.726410199130148\n",
      "Iteration: 20400, error: 6.645154039632071\n",
      "Iteration: 20500, error: 6.559734521106898\n",
      "Iteration: 20600, error: 6.488533630181621\n",
      "Iteration: 20700, error: 6.405815270455009\n",
      "Iteration: 20800, error: 6.333844207798611\n",
      "Iteration: 20900, error: 6.2726838343986095\n",
      "Iteration: 21000, error: 6.1884284744154\n",
      "Iteration: 21100, error: 6.118100849360688\n",
      "Iteration: 21200, error: 6.054317493888254\n",
      "Iteration: 21300, error: 5.984194946641162\n",
      "Iteration: 21400, error: 5.910098730980669\n",
      "Iteration: 21500, error: 5.852864553624438\n",
      "Iteration: 21600, error: 5.7944696646759235\n",
      "Iteration: 21700, error: 5.7208427714431265\n",
      "Iteration: 21800, error: 5.660541759641014\n",
      "Iteration: 21900, error: 5.601509890498637\n",
      "Iteration: 22000, error: 5.5508804976837265\n",
      "Iteration: 22100, error: 5.507487583400571\n",
      "Iteration: 22200, error: 5.466015447134048\n",
      "Iteration: 22300, error: 5.406257646254453\n",
      "Iteration: 22400, error: 5.352975376889747\n",
      "Iteration: 22500, error: 5.297916872529715\n",
      "Iteration: 22600, error: 5.239614841665391\n",
      "Iteration: 22700, error: 5.191516202602089\n",
      "Iteration: 22800, error: 5.1377171647729485\n",
      "Iteration: 22900, error: 5.091189700412539\n",
      "Iteration: 23000, error: 5.038744802558617\n",
      "Iteration: 23100, error: 4.986003210279036\n",
      "Iteration: 23200, error: 4.948085048764645\n",
      "Iteration: 23300, error: 4.892903299684511\n",
      "Iteration: 23400, error: 4.845747364074367\n",
      "Iteration: 23500, error: 4.796784070907879\n",
      "Iteration: 23600, error: 4.76483744296055\n",
      "Iteration: 23700, error: 4.719079603199501\n",
      "Iteration: 23800, error: 4.680237297847554\n",
      "Iteration: 23900, error: 4.649962101803967\n",
      "Iteration: 24000, error: 4.618227456123293\n",
      "Iteration: 24100, error: 4.591179730269239\n",
      "Iteration: 24200, error: 4.5554818681220794\n",
      "Iteration: 24300, error: 4.527200787261302\n",
      "Iteration: 24400, error: 4.487324657967641\n",
      "Iteration: 24500, error: 4.454994805108788\n",
      "Iteration: 24600, error: 4.418761193474803\n",
      "Iteration: 24700, error: 4.385728142151735\n",
      "Iteration: 24800, error: 4.353501794892576\n",
      "Iteration: 24900, error: 4.319156573279843\n",
      "Iteration: 25000, error: 4.294763306201155\n",
      "Iteration: 25100, error: 4.26294690976505\n",
      "Iteration: 25200, error: 4.233584346501174\n",
      "Iteration: 25300, error: 4.211129135554195\n",
      "Iteration: 25400, error: 4.176563249100136\n",
      "Iteration: 25500, error: 4.154774216222804\n",
      "Iteration: 25600, error: 4.133107690191389\n",
      "Iteration: 25700, error: 4.101385683993155\n",
      "Iteration: 25800, error: 4.0813746093069945\n",
      "Iteration: 25900, error: 4.056722424039035\n",
      "Iteration: 26000, error: 4.036773600334658\n",
      "Iteration: 26100, error: 4.013547040362159\n",
      "Iteration: 26200, error: 3.985636423034301\n",
      "Iteration: 26300, error: 3.9667169233569615\n",
      "Iteration: 26400, error: 3.943693903055797\n",
      "Iteration: 26500, error: 3.923798342967617\n",
      "Iteration: 26600, error: 3.907167943259162\n",
      "Iteration: 26700, error: 3.885486221329992\n",
      "Iteration: 26800, error: 3.8612070008231343\n",
      "Iteration: 26900, error: 3.8403562498043766\n",
      "Iteration: 27000, error: 3.82212526838367\n",
      "Iteration: 27100, error: 3.808195552803618\n",
      "Iteration: 27200, error: 3.7848688027484285\n",
      "Iteration: 27300, error: 3.761620798818446\n",
      "Iteration: 27400, error: 3.742696130240414\n",
      "Iteration: 27500, error: 3.7257708391016\n",
      "Iteration: 27600, error: 3.7089449622047503\n",
      "Iteration: 27700, error: 3.683666502169005\n",
      "Iteration: 27800, error: 3.669358123735441\n",
      "Iteration: 27900, error: 3.651493799898039\n",
      "Iteration: 28000, error: 3.636627003786268\n",
      "Iteration: 28100, error: 3.6216360019023512\n",
      "Iteration: 28200, error: 3.6049626625125906\n",
      "Iteration: 28300, error: 3.589293465019667\n",
      "Iteration: 28400, error: 3.5660624565453505\n",
      "Iteration: 28500, error: 3.5453207308567802\n",
      "Iteration: 28600, error: 3.5328689185918005\n",
      "Iteration: 28700, error: 3.5201308987411766\n",
      "Iteration: 28800, error: 3.5066536484162656\n",
      "Iteration: 28900, error: 3.4844818696200033\n",
      "Iteration: 29000, error: 3.4730290092625102\n",
      "Iteration: 29100, error: 3.4610888219580174\n",
      "Iteration: 29200, error: 3.442481292959434\n",
      "Iteration: 29300, error: 3.429621886693724\n",
      "Iteration: 29400, error: 3.4188489371141957\n",
      "Iteration: 29500, error: 3.403930912492249\n",
      "Iteration: 29600, error: 3.387199721366327\n",
      "Iteration: 29700, error: 3.382555199831846\n",
      "Iteration: 29800, error: 3.3689287812345503\n",
      "Iteration: 29900, error: 3.3604002791542946\n",
      "Iteration: 30000, error: 3.3472866816788223\n",
      "Iteration: 30100, error: 3.3386035550878845\n",
      "Iteration: 30200, error: 3.3328025308473803\n",
      "Iteration: 30300, error: 3.3231575605091224\n",
      "Iteration: 30400, error: 3.3091473920462158\n",
      "Iteration: 30500, error: 3.3005834870228727\n",
      "Iteration: 30600, error: 3.2879820438701164\n",
      "Iteration: 30700, error: 3.2818865843192775\n",
      "Iteration: 30800, error: 3.271186371386747\n",
      "Iteration: 30900, error: 3.26137497057454\n",
      "Iteration: 31000, error: 3.2495099704390658\n",
      "Iteration: 31100, error: 3.2396646763042907\n",
      "Iteration: 31200, error: 3.230269993150057\n",
      "Iteration: 31300, error: 3.2252195525236855\n",
      "Iteration: 31400, error: 3.2210405891365776\n",
      "Iteration: 31500, error: 3.2098564937940184\n",
      "Iteration: 31600, error: 3.2041020658355888\n",
      "Iteration: 31700, error: 3.1988962507816767\n",
      "Iteration: 31800, error: 3.1932342958071285\n",
      "Iteration: 31900, error: 3.185661578199507\n",
      "Iteration: 32000, error: 3.179166586256894\n",
      "Iteration: 32100, error: 3.170034479237322\n",
      "Iteration: 32200, error: 3.1611240029159307\n",
      "Iteration: 32300, error: 3.1533262110685376\n",
      "Iteration: 32400, error: 3.1446824103456557\n",
      "Iteration: 32500, error: 3.137680375429426\n",
      "Iteration: 32600, error: 3.128540458298588\n",
      "Iteration: 32700, error: 3.1227674547844946\n",
      "Iteration: 32800, error: 3.1131042645810068\n",
      "Iteration: 32900, error: 3.1070486600044274\n",
      "Iteration: 33000, error: 3.102084018048203\n",
      "Iteration: 33100, error: 3.0935346433207416\n",
      "Iteration: 33200, error: 3.0859919609859947\n",
      "Iteration: 33300, error: 3.078448532221588\n",
      "Iteration: 33400, error: 3.0731708323165274\n",
      "Iteration: 33500, error: 3.0680345323042433\n",
      "Iteration: 33600, error: 3.0642494702050556\n",
      "Iteration: 33700, error: 3.0600900224869436\n",
      "Iteration: 33800, error: 3.055379725726712\n",
      "Iteration: 33900, error: 3.0508322925940865\n",
      "Iteration: 34000, error: 3.045470764220032\n",
      "Iteration: 34100, error: 3.0400443899088367\n",
      "Iteration: 34200, error: 3.0318053020726783\n",
      "Iteration: 34300, error: 3.0262417966762496\n",
      "Iteration: 34400, error: 3.019353734577627\n",
      "Iteration: 34500, error: 3.0175227344806745\n",
      "Iteration: 34600, error: 3.0132728561496505\n",
      "Iteration: 34700, error: 3.0111872569433924\n",
      "Iteration: 34800, error: 3.0097703612094655\n",
      "Iteration: 34900, error: 3.005752495294254\n",
      "Iteration: 35000, error: 3.0006366540938156\n",
      "Iteration: 35100, error: 2.995496144495352\n",
      "Iteration: 35200, error: 2.9923063876356815\n",
      "Iteration: 35300, error: 2.9875961930104613\n",
      "Iteration: 35400, error: 2.983888642078109\n",
      "Iteration: 35500, error: 2.9797353399905195\n",
      "Iteration: 35600, error: 2.9774379554909354\n",
      "Iteration: 35700, error: 2.975427584356404\n",
      "Iteration: 35800, error: 2.972890649035693\n",
      "Iteration: 35900, error: 2.9686097611655633\n",
      "Iteration: 36000, error: 2.9646342114149014\n",
      "Iteration: 36100, error: 2.963296977095202\n",
      "Iteration: 36200, error: 2.959216741355789\n",
      "Iteration: 36300, error: 2.9567021317547604\n",
      "Iteration: 36400, error: 2.9527307223226797\n",
      "Iteration: 36500, error: 2.950183586582707\n",
      "Iteration: 36600, error: 2.9473553866962083\n",
      "Iteration: 36700, error: 2.9454268870089253\n",
      "Iteration: 36800, error: 2.940810210865503\n",
      "Iteration: 36900, error: 2.938091201250166\n",
      "Iteration: 37000, error: 2.9362936909374144\n",
      "Iteration: 37100, error: 2.934358490058221\n",
      "Iteration: 37200, error: 2.931284914007642\n",
      "Iteration: 37300, error: 2.928203944912552\n",
      "Iteration: 37400, error: 2.9249349957274013\n",
      "Iteration: 37500, error: 2.9222177175167108\n",
      "Iteration: 37600, error: 2.920098309048262\n",
      "Iteration: 37700, error: 2.9176477717670433\n",
      "Iteration: 37800, error: 2.9140163691788596\n",
      "Iteration: 37900, error: 2.9120214025128415\n",
      "Iteration: 38000, error: 2.9095974762571495\n",
      "Iteration: 38100, error: 2.907110421147724\n",
      "Iteration: 38200, error: 2.9051350549797825\n",
      "Iteration: 38300, error: 2.905543686145668\n",
      "Iteration: 38400, error: 2.9049027870573547\n",
      "Iteration: 38500, error: 2.9027450467598994\n",
      "Iteration: 38600, error: 2.899918323896893\n",
      "Iteration: 38700, error: 2.89765735758921\n",
      "Iteration: 38800, error: 2.8944567042185154\n",
      "Iteration: 38900, error: 2.891334448182731\n",
      "Iteration: 39000, error: 2.8888473829087853\n",
      "Iteration: 39100, error: 2.886799942555773\n",
      "Iteration: 39200, error: 2.8840166405815086\n",
      "Iteration: 39300, error: 2.8819381937532262\n",
      "Iteration: 39400, error: 2.879619929441727\n",
      "Iteration: 39500, error: 2.8768888593276642\n",
      "Iteration: 39600, error: 2.8751017276492523\n",
      "Iteration: 39700, error: 2.8724069754648855\n",
      "Iteration: 39800, error: 2.8707708727368275\n",
      "Iteration: 39900, error: 2.8677107574520484\n",
      "Iteration: 40000, error: 2.8669060513236038\n",
      "Iteration: 40100, error: 2.865010585218787\n",
      "Iteration: 40200, error: 2.8630849944147085\n",
      "Iteration: 40300, error: 2.863500522107405\n",
      "Iteration: 40400, error: 2.8626959490153223\n",
      "Iteration: 40500, error: 2.8628147019448664\n",
      "Iteration: 40600, error: 2.860056415538348\n",
      "Iteration: 40700, error: 2.8575807946509983\n",
      "Iteration: 40800, error: 2.855846882458739\n",
      "Iteration: 40900, error: 2.8539763975229393\n",
      "Iteration: 41000, error: 2.8537815362723755\n",
      "Iteration: 41100, error: 2.8541177208574893\n",
      "Iteration: 41200, error: 2.8516481810876133\n",
      "Iteration: 41300, error: 2.849362273875874\n",
      "Iteration: 41400, error: 2.8490380180556394\n",
      "Iteration: 41500, error: 2.8470358841784313\n",
      "Iteration: 41600, error: 2.8457094984164457\n",
      "Iteration: 41700, error: 2.8443585439196175\n",
      "Iteration: 41800, error: 2.8445632824467175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 41900, error: 2.844397207226082\n",
      "Iteration: 42000, error: 2.8428466104069914\n",
      "Iteration: 42100, error: 2.841108510961665\n",
      "Iteration: 42200, error: 2.8405926014091314\n",
      "Iteration: 42300, error: 2.839287095575137\n",
      "Iteration: 42400, error: 2.838762054934045\n",
      "Iteration: 42500, error: 2.8380035150401888\n",
      "Iteration: 42600, error: 2.836397659421974\n",
      "Iteration: 42700, error: 2.835774329373564\n",
      "Iteration: 42800, error: 2.8353034613657924\n",
      "Iteration: 42900, error: 2.8339652919032305\n",
      "Iteration: 43000, error: 2.833287398128437\n",
      "Iteration: 43100, error: 2.832264565971881\n",
      "Iteration: 43200, error: 2.8305542474053054\n",
      "Iteration: 43300, error: 2.8291858468139877\n",
      "Iteration: 43400, error: 2.828439979480562\n",
      "Iteration: 43500, error: 2.828918109648033\n",
      "Iteration: 43600, error: 2.82763462998788\n",
      "Iteration: 43700, error: 2.8262393702224426\n",
      "Iteration: 43800, error: 2.825873828437242\n",
      "Iteration: 43900, error: 2.8257553665780257\n",
      "Iteration: 44000, error: 2.8256858635990363\n",
      "Iteration: 44100, error: 2.8246005015939515\n",
      "Iteration: 44200, error: 2.8228727293370963\n",
      "Iteration: 44300, error: 2.822278455378458\n",
      "Iteration: 44400, error: 2.8218158951989794\n",
      "Iteration: 44500, error: 2.822139106276978\n",
      "Iteration: 44600, error: 2.8214773826310386\n",
      "Iteration: 44700, error: 2.8211334095858174\n",
      "Iteration: 44800, error: 2.820384561661401\n",
      "Iteration: 44900, error: 2.8185443838015964\n",
      "Iteration: 45000, error: 2.8180165912436927\n",
      "Iteration: 45100, error: 2.8182613520398934\n",
      "Iteration: 45200, error: 2.8176777685098138\n",
      "Iteration: 45300, error: 2.816345823584904\n",
      "Iteration: 45400, error: 2.8156233642711936\n",
      "Iteration: 45500, error: 2.8145519554565306\n",
      "Iteration: 45600, error: 2.8142846231070915\n",
      "Iteration: 45700, error: 2.8144033622100197\n",
      "Iteration: 45800, error: 2.8139647671633954\n",
      "Iteration: 45900, error: 2.8131398605192937\n",
      "Iteration: 46000, error: 2.813204292465241\n",
      "Iteration: 46100, error: 2.8119758528240824\n",
      "Iteration: 46200, error: 2.81138212132494\n",
      "Iteration: 46300, error: 2.810712060788055\n",
      "Iteration: 46400, error: 2.8110632252141645\n",
      "Iteration: 46500, error: 2.8105147979996175\n",
      "Iteration: 46600, error: 2.8109079868418525\n",
      "Iteration: 46700, error: 2.8103582906940714\n",
      "Iteration: 46800, error: 2.8101247023885536\n",
      "Iteration: 46900, error: 2.809038442791498\n",
      "Iteration: 47000, error: 2.8076381066649465\n",
      "Iteration: 47100, error: 2.806436681293346\n",
      "Iteration: 47200, error: 2.8060978801866607\n",
      "Iteration: 47300, error: 2.805812531455921\n",
      "Iteration: 47400, error: 2.805827677611478\n",
      "Iteration: 47500, error: 2.8054137798418775\n",
      "Iteration: 47600, error: 2.8044114970478695\n",
      "Iteration: 47700, error: 2.80367642284481\n",
      "Iteration: 47800, error: 2.8025104006760477\n",
      "Iteration: 47900, error: 2.8010202609957684\n",
      "Iteration: 48000, error: 2.800984175375386\n",
      "Iteration: 48100, error: 2.8006613480945934\n",
      "Iteration: 48200, error: 2.8002653868870446\n",
      "Iteration: 48300, error: 2.799783769793404\n",
      "Iteration: 48400, error: 2.799316220686652\n",
      "Iteration: 48500, error: 2.798923336595563\n",
      "Iteration: 48600, error: 2.799001722498637\n",
      "Iteration: 48700, error: 2.798254994008381\n",
      "Iteration: 48800, error: 2.7977783019179245\n",
      "Iteration: 48900, error: 2.7971735714346226\n",
      "Iteration: 49000, error: 2.7978498933662657\n",
      "Iteration: 49100, error: 2.7974786655442303\n",
      "Iteration: 49200, error: 2.797170741401229\n",
      "Iteration: 49300, error: 2.7971268243985232\n",
      "Iteration: 49400, error: 2.796946645944712\n",
      "Iteration: 49500, error: 2.7968692260898536\n",
      "Iteration: 49600, error: 2.7964489960206764\n",
      "Iteration: 49700, error: 2.7959808401406208\n",
      "Iteration: 49800, error: 2.795984678888894\n",
      "Iteration: 49900, error: 2.7958503144231828\n",
      "Iteration: 50000, error: 2.7946913999811356\n",
      "Iteration: 50100, error: 2.794694734532139\n",
      "Iteration: 50200, error: 2.7943101490267304\n",
      "Iteration: 50300, error: 2.794436728029086\n",
      "Iteration: 50400, error: 2.7943925936297878\n",
      "Iteration: 50500, error: 2.794207561596536\n",
      "Iteration: 50600, error: 2.793780110280943\n",
      "Iteration: 50700, error: 2.793550658069248\n",
      "Iteration: 50800, error: 2.7933581597633164\n",
      "Iteration: 50900, error: 2.7932888563817424\n",
      "Iteration: 51000, error: 2.792570809196633\n",
      "Iteration: 51100, error: 2.7925767934660772\n",
      "Iteration: 51200, error: 2.7918798265603084\n",
      "Iteration: 51300, error: 2.7921221075950857\n",
      "Iteration: 51400, error: 2.792095858487298\n",
      "Iteration: 51500, error: 2.7919072835771455\n",
      "Iteration: 51600, error: 2.7918518578529965\n",
      "Iteration: 51700, error: 2.791800110446646\n",
      "Iteration: 51800, error: 2.791148151929233\n",
      "Iteration: 51900, error: 2.7907429448322607\n",
      "Iteration: 52000, error: 2.7910029077666287\n",
      "Iteration: 52100, error: 2.7909284904751424\n",
      "Iteration: 52200, error: 2.790666537786958\n",
      "Iteration: 52300, error: 2.790602899485953\n",
      "Iteration: 52400, error: 2.7905217581960353\n",
      "Iteration: 52500, error: 2.790555093563246\n",
      "Iteration: 52600, error: 2.790598208940762\n",
      "Iteration: 52700, error: 2.790584440374987\n",
      "Iteration: 52800, error: 2.7905047721481004\n",
      "Iteration: 52900, error: 2.790605852320281\n",
      "Iteration: 53000, error: 2.790839675882466\n",
      "Iteration: 53100, error: 2.790404771907595\n",
      "Iteration: 53200, error: 2.790101532666471\n",
      "Iteration: 53300, error: 2.7904242138577127\n",
      "Iteration: 53400, error: 2.790268181725448\n",
      "Iteration: 53500, error: 2.7906531584515166\n",
      "Iteration: 53600, error: 2.790256151300505\n",
      "Iteration: 53700, error: 2.7901034367494915\n",
      "Iteration: 53800, error: 2.790377344337139\n",
      "Iteration: 53900, error: 2.7902693304502204\n",
      "Iteration: 54000, error: 2.790025808179349\n",
      "Iteration: 54100, error: 2.7905140336267182\n",
      "Iteration: 54200, error: 2.79043062867143\n",
      "Iteration: 54300, error: 2.7903708253026234\n",
      "Iteration: 54400, error: 2.790335090191412\n",
      "Iteration: 54500, error: 2.790533076914754\n",
      "Iteration: 54600, error: 2.790033682855078\n",
      "Iteration: 54700, error: 2.7901223401802464\n",
      "Iteration: 54800, error: 2.7900318995715048\n",
      "Iteration: 54900, error: 2.789987206877333\n",
      "Iteration: 55000, error: 2.7899805492140057\n",
      "Iteration: 55100, error: 2.790089818847625\n",
      "Iteration: 55200, error: 2.789900296218226\n",
      "Iteration: 55300, error: 2.7902336196990247\n",
      "Iteration: 55400, error: 2.790320915906479\n",
      "Iteration: 55500, error: 2.790074488366762\n",
      "Iteration: 55600, error: 2.7899297308483404\n",
      "Iteration: 55700, error: 2.790070671749991\n",
      "Iteration: 55800, error: 2.790029364467986\n",
      "Iteration: 55900, error: 2.7894703359686064\n",
      "Iteration: 56000, error: 2.789367360657805\n",
      "Iteration: 56100, error: 2.7895943037400945\n",
      "Iteration: 56200, error: 2.7894005758891733\n",
      "Iteration: 56300, error: 2.7892103281316127\n",
      "Iteration: 56400, error: 2.7892531802326004\n",
      "Iteration: 56500, error: 2.7895561015843806\n",
      "Iteration: 56600, error: 2.7896575272925794\n",
      "Iteration: 56700, error: 2.7890940748199284\n",
      "Iteration: 56800, error: 2.7888914199331243\n",
      "Iteration: 56900, error: 2.7890452202097076\n",
      "Iteration: 57000, error: 2.788946101982118\n",
      "Iteration: 57100, error: 2.7890871340449377\n",
      "Iteration: 57200, error: 2.7888922697105754\n",
      "Iteration: 57300, error: 2.7887115360024075\n",
      "Iteration: 57400, error: 2.788824457904892\n",
      "Iteration: 57500, error: 2.7887719990310327\n",
      "Iteration: 57600, error: 2.7883991056846607\n",
      "Iteration: 57700, error: 2.788429233874658\n",
      "Iteration: 57800, error: 2.788182113036554\n",
      "Iteration: 57900, error: 2.788239339889044\n",
      "Iteration: 58000, error: 2.7880342884102673\n",
      "Iteration: 58100, error: 2.7880724716248664\n",
      "Iteration: 58200, error: 2.7881647960431777\n",
      "Iteration: 58300, error: 2.788252904319849\n",
      "Iteration: 58400, error: 2.7883286829613336\n",
      "Iteration: 58500, error: 2.787956335962187\n",
      "Iteration: 58600, error: 2.7882034542305894\n",
      "Iteration: 58700, error: 2.787863384195897\n",
      "Iteration: 58800, error: 2.7877833783485464\n",
      "Iteration: 58900, error: 2.787602075866523\n",
      "Iteration: 59000, error: 2.787538770271734\n",
      "Iteration: 59100, error: 2.7877061569284853\n",
      "Iteration: 59200, error: 2.787686694745538\n",
      "Iteration: 59300, error: 2.787370267297098\n",
      "Iteration: 59400, error: 2.7874580379538076\n",
      "Iteration: 59500, error: 2.7871161091484993\n",
      "Iteration: 59600, error: 2.787288154661195\n",
      "Iteration: 59700, error: 2.787373518709083\n",
      "Iteration: 59800, error: 2.786815246275578\n",
      "Iteration: 59900, error: 2.7869203657201593\n",
      "Iteration: 60000, error: 2.78692124517896\n",
      "Iteration: 60100, error: 2.7870168443133707\n",
      "Iteration: 60200, error: 2.787211210273885\n",
      "Iteration: 60300, error: 2.787233323552542\n",
      "Iteration: 60400, error: 2.787358250578068\n",
      "Iteration: 60500, error: 2.7871926597247314\n",
      "Iteration: 60600, error: 2.7870763924737605\n",
      "Iteration: 60700, error: 2.787040545776961\n",
      "Iteration: 60800, error: 2.787332383922099\n",
      "Iteration: 60900, error: 2.787279085967931\n",
      "Iteration: 61000, error: 2.7875848621845125\n",
      "Iteration: 61100, error: 2.7873240390656746\n",
      "Iteration: 61200, error: 2.787416640158449\n",
      "Iteration: 61300, error: 2.7873236981694323\n",
      "Iteration: 61400, error: 2.787306398181029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 61500, error: 2.787331638152663\n",
      "Iteration: 61600, error: 2.787225861894227\n",
      "Iteration: 61700, error: 2.7870806235451484\n",
      "Iteration: 61800, error: 2.787264001045177\n",
      "Iteration: 61900, error: 2.7872609305023626\n",
      "Iteration: 62000, error: 2.7870663823627813\n",
      "Iteration: 62100, error: 2.7870072574009135\n",
      "Iteration: 62200, error: 2.7873639361493154\n",
      "Iteration: 62300, error: 2.7875202562914065\n",
      "Iteration: 62400, error: 2.787354308475136\n",
      "Iteration: 62500, error: 2.7872391989562026\n",
      "Iteration: 62600, error: 2.7870774999086017\n",
      "Iteration: 62700, error: 2.7871342325573845\n",
      "Iteration: 62800, error: 2.787113513540031\n",
      "Iteration: 62900, error: 2.7873368501712514\n",
      "Iteration: 63000, error: 2.7873934753438028\n",
      "Iteration: 63100, error: 2.7877222202325695\n",
      "Iteration: 63200, error: 2.7877218513581408\n",
      "Iteration: 63300, error: 2.7875747141312917\n",
      "Iteration: 63400, error: 2.7873246007924983\n",
      "Iteration: 63500, error: 2.787156266210343\n",
      "Iteration: 63600, error: 2.7872659027712046\n",
      "Wall time: 3.25 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "stoch_grad_desc_weights, stoch_errors_by_iter = stochastic_gradient_descent(X, y, np.zeros((4, 1)), eta=0.01,\n",
    "                                                                           max_iter=1e5, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Посмотрим, чему равна ошибка на первых 50 итерациях стохастического градиентного спуска. Видим, что ошибка не обязательно уменьшается на каждой итерации.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'MSE')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pylab inline\n",
    "plot(range(50), stoch_errors_by_iter[:50])\n",
    "xlabel('Iteration number')\n",
    "ylabel('MSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Теперь посмотрим на зависимость ошибки от номера итерации для $10^5$ итераций стохастического градиентного спуска. Видим, что алгоритм сходится.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'MSE')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAZe0lEQVR4nO3de5RdZZ2n8edXVUkIAUxCLkQCVKCDEBUBqzGA2jAE5dIt2t7AoQmIi7bVVmxnteBlnJ413Yseu+2WwVvaC9gDKGMjMshVbg5eAhWMIQgJAUJSJCQFJCGBkOs7f+y35BDPqU1CTp2q2s9nrbPO3u/Zl3dnV+pb+93veXeklJAkaUdtra6AJGlwMiAkSXUZEJKkugwISVJdBoQkqa6OVlfg1ZgwYULq7OxsdTUkaUiZN2/e0ymliWXLDemA6OzspLu7u9XVkKQhJSKeeCXL2cQkSarLgJAk1WVASJLqMiAkSXUZEJKkugwISVJdBoQkqa5KBsTiVev5yq2LeHrDplZXRZIGrUoGxCOrNnDpHUt49vnNra6KJA1alQwISVK5SgeED9OTpMYqGRARra6BJA1+lQwISVK5SgdEwjYmSWqkkgFhC5MklatkQEiSylU6IOzFJEmNVTIg7MUkSeWaFhARcUBE3BkRD0XEgxHxqVw+PiJui4hH8vu4XB4RcWlELImIBRFxdLPqJkkq18wriK3AZ1JKhwMzgY9HxAzgIuD2lNJ04PY8D3AqMD2/LgC+0cS6SZJKNC0gUkorU0r35+n1wEPA/sAZwBV5sSuAd+fpM4Dvp8KvgbERMaVZ9Svq1cytS9LQNiD3ICKiEzgKmAtMTimthCJEgEl5sf2B5TWr9eSyHbd1QUR0R0R3b2/vrtZoF9eTpOpoekBExF7AfwAXppSe62/ROmV/8Dd+SmlOSqkrpdQ1ceLE3VVNSdIOmhoQETGCIhyuTCldm4tX9TUd5ffVubwHOKBm9anAimbWz29SS1JjzezFFMB3gIdSSl+p+eh6YHaeng38pKb8nNybaSawrq8pavfXrRlblaThpaOJ2z4e+AvggYiYn8s+B1wCXBMR5wPLgPfnz24ETgOWAC8A5zWxbpKkEk0LiJTSPTS+G3xSneUT8PFm1aceezFJUmPV/CZ1qysgSUNAJQNCklTOgJAk1VXJgAi7MUlSqUoGhCSpXKUDwl5MktRYJQPCBiZJKlfJgJAklat0QDgWkyQ1VsmAsBOTJJWrZEBIkspVOiDsxSRJjVUyIGxikqRylQwISVI5A0KSVFelA8JbEJLUWCUDIvwutSSVqmRASJLKVTogkv1cJamhagaELUySVKqaASFJKlXpgLCBSZIaq2RA2MIkSeUqGRCSpHKVDgg7MUlSY5UMiHC0PkkqVcmAkCSVq3hA2MYkSY1UMiBsYJKkcpUMCElSuUoHhL2YJKmxSgaEnZgkqVwlA0KSVM6AkCTVVemA8BaEJDVWyYDwkaOSVK6SASFJKlfpgLCbqyQ11rSAiIjvRsTqiFhYU/bfIuLJiJifX6fVfHZxRCyJiEUR8c5m1avYVzO3LknDQzOvIC4HTqlT/i8ppSPz60aAiJgBnAm8Pq/z9Yhob2LdJEklmhYQKaWfA8++wsXPAH6QUtqUUnocWAIc06y69Um2MUlSQ624B/GJiFiQm6DG5bL9geU1y/Tksj8QERdERHdEdPf29u5SBWxhkqRyAx0Q3wAOAY4EVgL/nMvr/c6u++d9SmlOSqkrpdQ1ceLE5tRSkjSwAZFSWpVS2pZS2g78Gy81I/UAB9QsOhVY0fT6NHsHkjSEDWhARMSUmtn3AH09nK4HzoyIURExDZgO3Nu8ijRty5I0bHQ0a8MRcTVwAjAhInqALwEnRMSRFH+8LwX+EiCl9GBEXAP8DtgKfDyltK1ZdZMklWtaQKSUzqpT/J1+lv974O+bVZ/6+xzIvUnS0FLJb1I7FpMklatkQEiSylU6IJL9mCSpoUoGhGMxSVK5SgaEJKlctQPCFiZJaqiSAWELkySVq2RASJLKGRCSpLoqHRDegpCkxioZEGE/V0kqVcmAkCSVq3RAOFifJDVWyYCwhUmSylUyICRJ5SodEA7WJ0mNVTIgbGGSpHKVDAhJUrlKB4S9mCSpsUoGhL2YJKlcJQNCklSu0gFhC5MkNVbRgLCNSZLKVDQgJEllKh0QyW5MktRQvwEREWfXTB+/w2efaFalms1eTJJUruwK4m9qpv/XDp99eDfXRZI0iJQFRDSYrjc/5NjAJEmNlQVEajBdb37IGPLJJkkDoKPk88MiYgHF79RD8jR5/uCm1kyS1FJlAXH4gNRCkjTo9BsQKaUnaucjYl/g7cCylNK8ZlZsQAzZRjJJar6ybq43RMQb8vQUYCFF76V/j4gLB6B+TRH2c5WkUmU3qaellBbm6fOA21JKfwa8Bbu5StKwVhYQW2qmTwJuBEgprQe2N6tSA8VHjkpSY2U3qZdHxF8DPcDRwM0AETEaGNHkujWNDUySVK7sCuJ84PXAucAHU0prc/lM4HtNrJckqcXKejGtBj5ap/xO4M5mVWqgOFafJDXWb0BExPX9fZ5Selc/634X+FNgdUqpryfUeOCHQCewFPhASmlNFN2KvgqcBrwAnJtSuv+VH8bOsROTJJUruwdxLLAcuBqYy841318OXAZ8v6bsIuD2lNIlEXFRnv8scCowPb/eAnwjv0uSWqTsHsR+wOeAN1D8hX8y8HRK6e6U0t39rZhS+jnw7A7FZwBX5OkrgHfXlH8/FX4NjM3fu2gqm5gkqbF+AyKltC2ldHNKaTbFjeklwF25Z9OumJxSWpm3vRKYlMv3p7hS6dOTy/5ARFwQEd0R0d3b27tLlQj7MUlSqbImJiJiFHA6cBbFvYNLgWt3cz3q/cau+/d9SmkOMAegq6vLawBJapKym9RXUDQv3QT8Xc23qnfVqoiYklJamZuQVufyHuCAmuWmAite5b5KmS6S1FjZPYi/AA4FPgX8MiKey6/1EfHcLuzvemB2np4N/KSm/JwozATW9TVFNYO9mCSpXNn3IMoCpKGIuBo4AZgQET3Al4BLgGsi4nxgGfD+vPiNFF1cl1B0cz1vV/crSdo9Su9B7KqU0lkNPjqpzrIJ+Hiz6tJIshuTJDW0y1cIkqThzYCQJNVV6YCwgUmSGqtkQNiLSZLKVTIgJEnlDAhJUl2VDgh7uUpSY5UMCAfrk6RylQwISVK5igeEbUyS1EglA8JurpJUrpIBIUkqV+mAsBeTJDVWyYCwiUmSylUyICRJ5SodELYwSVJjlQwIvygnSeUqGRCSpHKVDgh7MUlSY5UMCHsxSVK5SgaEJKlcpQMi2Y9JkhqqZEDYwiRJ5SoZEJKkcpUOCHsxSVJjlQ4ISVJjlQwIu7lKUrlKBoQkqVylA8JbEJLUWEUDwjYmSSpT0YCQJJWpdEAk+7lKUkOVDAh7MUlSuUoGhCSpnAEhSaqrkgFhC5MklatkQEiSylU6IOzEJEmNdbRipxGxFFgPbAO2ppS6ImI88EOgE1gKfCCltKZJ+2/GZiVpWGnlFcSJKaUjU0pdef4i4PaU0nTg9jwvSWqRwdTEdAZwRZ6+Anh3s3foI0clqbFWBUQCbo2IeRFxQS6bnFJaCZDfJ9VbMSIuiIjuiOju7e3dpZ3bwCRJ5VpyDwI4PqW0IiImAbdFxMOvdMWU0hxgDkBXV5eXAJLUJC25gkgprcjvq4EfA8cAqyJiCkB+X938ejR7D5I0dA14QETEmIjYu28aeAewELgemJ0Xmw38pHl1aNaWJWn4aEUT02Tgx7mraQdwVUrp5oi4D7gmIs4HlgHvb0HdJEnZgAdESukx4E11yp8BThro+kiS6htM3VwHnPcgJKmxSgZE2NFVkkpVMiAkSeUqHRC2MElSY5UMCLu5SlK5SgaEJKlcpQMi2Y1JkhqqdEBIkhozICRJdVU6IGxgkqTGKhkQ9mKSpHKVDAhJUrlqB4RtTJLUUCUDImxjkqRSlQwISVK5SgdEso1JkhqqZEDYwCRJ5SoZEJKkcpUOCIdikqTGKhkQdmKSpHKVDAhJUjkDQpJUV6UDwlsQktRYJQMi7OgqSaUqGRCSpHKVDIi2fAGxbbuNTJLUSDUDIifEdr8IIUkNVTIgOnJAeAUhSY1VMiDaDQhJKlXJgOhoKw57qwEhSQ1VMiC8gpCkcpUMiL57EFu3GRCS1EglA6KtLYiAbdu3t7oqkjRoVTIgoLiK8B6EJDVW2YBoi/AehCT1o7IBsWnrdnrWbmx1NSRp0OpodQVa6acLVvJf3vE89zzSy3XzV3DkAWP5zj2Pc9mHjmLj5m28Zdq+vP3Ld7LXqA7+65/N4P4n1nDHw6v59MmHMqqjjX/7f49z8IQxjBnVzowp+/Di1u1cctPDALznqP3Zsm07k/beg6MPGpu71iYW9Kzj63c9CsD73zyVzgljmPv4s/x8cS8HTxzDMZ3j+cF9y/nqmUeyYdNWTnn9fqzduIWn1r3IN+9+lCfXbOTEwybxJ4dOZOv27dzzyDN0dY7joH335PRL7+HgCWMYu+cI/uHP38hzG7dyTfdyug4ax00Ln2LW4ZPYsGkbI9qDM485kLaAR1c/z22/e4pZMyazZPUGRna0MX7PkSxcsY5/uPFhvnD64dz64CoWrVrPuo1b+PL7jmDW4ZNJwIq1G4mAy+5YwlnHHMjIjjbOnPNrbv/MnxDAU8+9yJNrNjJqRDuPrFrPvY8/y7btifuXreHsmQcx97FnWbtxM6ue28RlHzqKU98whe/94nH+x08fAuBjJxzC6BHtvO3QiWzeup2bFq5kZEcbM6bsw+JV61n69Aucc+xB3PLgKibsPZKR7W2cPfMgetdvYkHPOlau28j6F7fy2rF70NHWxqJV6znlDfvx51//JV84/XCmT96bgyeM4cEV6/jo/76f/fbZg/OO72T65L24/aHVXDl3Gd8794955vnN3LzwKe5Z0stnTzmMjvY2frNsDece18n181ewccs2PvSWA3nimRd44/6vYf7ytXTuO4Z7lz7LB7qmsnjVBr7/q6V89pTDOO6SOzjrmAM465gD6Vmzket+8ySzZkzm6nuXsWXbdk59wxTeNHUsj/Zu4HX77c2Vc5fxztdPZszIDlaue5Gr7n2CT5w4nZNnTGb+8jUsemoDHe3Bxs3b6Jwwhi1bt3PIpL1Y9dyLTJ+0F89v2sbdj/TyxesW8smTpjNuzxE8+/xmXti8jbdMG8+LW7ez9x4dvGnqWEa0Bz97aBWX//IJPnx8J/vsMYKeNS8AcOobp3DHQ6t57sUtHDF1LO1twb/ctph7ljzNpL1H8emTDyWA8WNG8qvHnmH0iHY+edJ05i9fyy+WPM0tDz7FGUfuz/vePJVr7lvOA0+u4zfL1zJhr1FM2nsUS1Zv4KYL38bdi3q5au4yLj7tMM7+9lwuee8RTNp7FBu3bOOIqWN5cMU6UoIbFqzk6nuXceGs6Yxob2PW4ZPpaA9++egzfPG6hQCc/9ZpvOtNr2XyPntw6ld/zlEHjmPquNGc+LpJTBm7B/c/sZZjD9mXny5YwT/dupiPvHUaRx04ji/+ZCEH7bsnn551KPuMHsGa5zdz3uX3ce3HjmPO3Y/R1gafP30Gy555gW3bE4futxej2tv5bc9aupc+y9sPnQjA3Yt7mX1cJ1fPXcZdi3s5Yupr6FmzkbNnHsTX7ljCe9+8P6e8fgprXtjMhy+/j67OcRx3yAQATjxsEp+55rdcOGs6vRs28aPuHo49ZF9mHT6ZtRs3M2ZkB1PHjSaa/PSzSINsuImIOAX4KtAOfDuldEmjZbu6ulJ3d/cu7afzop/uWgUlaZBYesnpu7ReRMxLKXWVLTeompgioh34GnAqMAM4KyJmNGNfx//Rvs3YrCQNiI+dcEjT9zHYmpiOAZaklB4DiIgfAGcAv9vdO7ryIzN39yYlaVgZVFcQwP7A8pr5nlwmSRpggy0g6t1xedlNkoi4ICK6I6K7t7d3gKolSdUz2AKiBzigZn4qsKJ2gZTSnJRSV0qpa+LEiQNaOUmqksEWEPcB0yNiWkSMBM4Erm9xnSSpkgbVTeqU0taI+ARwC0U31++mlB5scbUkqZIGVUAApJRuBG5sdT0kqeoGWxOTJGmQMCAkSXUNuqE2dkZE9AJP7OLqE4Cnd2N1hgKPuRo85mp4Ncd8UEqptBvokA6IVyMiul/JWCTDicdcDR5zNQzEMdvEJEmqy4CQJNVV5YCY0+oKtIDHXA0eczU0/Zgrew9CktS/Kl9BSJL6YUBIkuqqZEBExCkRsSgilkTERa2uz86IiAMi4s6IeCgiHoyIT+Xy8RFxW0Q8kt/H5fKIiEvzsS6IiKNrtjU7L/9IRMyuKX9zRDyQ17k0mv3g21coItoj4jcRcUOenxYRc3P9f5gHeCQiRuX5JfnzzpptXJzLF0XEO2vKB93PRESMjYgfRcTD+XwfO9zPc0R8Ov9cL4yIqyNij+F2niPiuxGxOiIW1pQ1/bw22ke/UkqVelEMAvgocDAwEvgtMKPV9dqJ+k8Bjs7TewOLKR7P+j+Bi3L5RcA/5unTgJsonrUxE5iby8cDj+X3cXl6XP7sXuDYvM5NwKmtPu5cr78BrgJuyPPXAGfm6W8Cf5WnPwZ8M0+fCfwwT8/I53sUMC3/HLQP1p8J4ArgI3l6JDB2OJ9nioeDPQ6Mrjm/5w638wy8HTgaWFhT1vTz2mgf/da11f8JWnByjgVuqZm/GLi41fV6FcfzE+BkYBEwJZdNARbl6W8BZ9Usvyh/fhbwrZryb+WyKcDDNeUvW66FxzkVuB34T8AN+Yf/aaBjx/NKMRrwsXm6Iy8XO57rvuUG488EsE/+ZRk7lA/b88xLT5Qcn8/bDcA7h+N5Bjp5eUA0/bw22kd/ryo2MQ2bx5rmS+qjgLnA5JTSSoD8Pikv1uh4+yvvqVPeav8K/C2wPc/vC6xNKW3N87X1/P2x5c/X5eV39t+ilQ4GeoHv5Wa1b0fEGIbxeU4pPQn8E7AMWElx3uYxvM9zn4E4r4320VAVA6L0saZDQUTsBfwHcGFK6bn+Fq1TlnahvGUi4k+B1SmlebXFdRZNJZ8NmWOm+Iv4aOAbKaWjgOcpmgUaGfLHnNvEz6BoFnotMAY4tc6iw+k8l2npMVYxIEofazrYRcQIinC4MqV0bS5eFRFT8udTgNW5vNHx9lc+tU55Kx0PvCsilgI/oGhm+ldgbET0PdOktp6/P7b8+WuAZ9n5f4tW6gF6Ukpz8/yPKAJjOJ/nWcDjKaXelNIW4FrgOIb3ee4zEOe10T4aqmJADOnHmuYeCd8BHkopfaXmo+uBvp4MsynuTfSVn5N7Q8wE1uXLy1uAd0TEuPyX2zso2mdXAusjYmbe1zk122qJlNLFKaWpKaVOivN1R0rpPwN3Au/Li+14zH3/Fu/Ly6dcfmbu/TINmE5xQ2/Q/UyklJ4ClkfE63LRScDvGMbnmaJpaWZE7Jnr1HfMw/Y81xiI89poH4218qZUq14UPQMWU/Ro+Hyr67OTdX8rxSXjAmB+fp1G0fZ6O/BIfh+flw/ga/lYHwC6arb1YWBJfp1XU94FLMzrXMYON0pbfPwn8FIvpoMp/uMvAf4PMCqX75Hnl+TPD65Z//P5uBZR02tnMP5MAEcC3flcX0fRW2VYn2fg74CHc73+naIn0rA6z8DVFPdYtlD8xX/+QJzXRvvo7+VQG5KkuqrYxCRJegUMCElSXQaEJKkuA0KSVJcBIUmqy4DQkBMRG/J7Z0R8aDdv+3M7zP9yd25/d4uIcyPislbXQ8OTAaGhrBPYqYCIiPaSRV4WECml43ayTkPKK/j3UIUZEBrKLgHeFhHzo3iOQHtEfDki7stj5/8lQEScEMUzNK6i+LIREXFdRMyL4tkDF+SyS4DReXtX5rK+q5XI216Yx9r/YM2274qXnttwZd/4+7XyMv8YEfdGxOKIeFsuf9kVQETcEBEn9O07rzMvIn4WEcfk7TwWEe+q2fwBEXFzFM85+FLNts7O+5sfEd/qC4O83f8eEXMpRjiV6mv1Nyd9+drZF7Ahv59A/lZ1nr8A+EKeHkXxLeRpebnngWk1y/Z9U3U0xbdO963ddp19vRe4jeKZApMphoWYkre9jmLMmzbgV8Bb69T5LuCf8/RpwM/y9LnAZTXL3QCckKcTL43l/2PgVmAE8CZgfs36Kym+Jdt3LF3A4cD/BUbk5b4OnFOz3Q+0+jz6GvyvvgGwpOHgHcAREdE3bs9rKMbh2Qzcm1J6vGbZT0bEe/L0AXm5Z/rZ9luBq1NK2ygGPbsb+GPgubztHoCImE/R9HVPnW30Daw4Ly9TZjNwc55+ANiUUtoSEQ/ssP5tKaVn8v6vzXXdCrwZuC9f0IzmpcHZtlEM9ij1y4DQcBLAX6eUbnlZYdFk8/wO87MoHjbzQkTcRTGuT9m2G9lUM72Nxv+vNtVZZisvb+qtrceWlFLfWDjb+9ZPKW2Pl0Y3hT8czrlv2OcrUkoX16nHiznopH55D0JD2XqKx672uQX4qyiGQyciDo3iITs7eg2wJofDYRSPcuyzpW/9Hfwc+GC+zzGR4rGR9+6GY1gKHBkRbRFxAHDMLmzj5CieNzwaeDfwC4rB2N4XEZPg988jPmg31FcV4hWEhrIFwNaI+C1wOfBViqaX+/ON4l6KX5g7uhn4aEQsoBjt89c1n80BFkTE/akYUrzPjylu6P6W4i/0v00pPZUD5tX4BcWjRR+guH9w/y5s4x6KkU//CLgqpdQNEBFfAG6NiDaKkUM/DjzxKuurCnE0V0lSXTYxSZLqMiAkSXUZEJKkugwISVJdBoQkqS4DQpJUlwEhSarr/wPfTxS/w6NunQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pylab inline\n",
    "plot(range(len(stoch_errors_by_iter)), stoch_errors_by_iter)\n",
    "xlabel('Iteration number')\n",
    "ylabel('MSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Посмотрим на вектор весов, к которому сошелся метод.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.88937085],\n",
       "       [ 3.14806802],\n",
       "       [ 0.18332595],\n",
       "       [13.97837992]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoch_grad_desc_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Посмотрим на среднеквадратичную ошибку на последней итерации.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.8733103478495448"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoch_errors_by_iter[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Какова среднеквадратичная ошибка прогноза значений Sales в виде линейной модели с весами, найденными с помощью градиентного спуска? Полученный результат, округленный до 3 знаков после запятой, является ответом на *'4 задание'*.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.787\n"
     ]
    }
   ],
   "source": [
    "answer4 = mserror(adver_data['Sales'], linear_prediction(X, stoch_grad_desc_weights))\n",
    "print(round(answer4, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
