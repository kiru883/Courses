# Backbones / classification
  - ResNet
  - VGG16
## Models
  ### ResNet
![](https://github.com/kiru883/Courses/blob/master/CV%20notes/images/resnet.PNG)

- **Основная мысль** - res. block(fig. c) вместо того чтоб аппроксимироваться к H(x)("идеальный" feature map), с помощью классических методов, апроксимируемся "остатками". 
Н(х) = F(x) + x, где х это инпут, F(x) это остаток, каждый блок использует пропуск соединения(shortcut), мое интуитивное понятие, ассоциация с град. бустингом, 
там мы тоже генерим ОСТАТКИ градиентов лосса и затем суммируем их с предиктом на начальном предикторе.
- **Fig. A** - основные архитектуры реснет сетей, конв блоки имеют same паддинг, размеры feature map'ов считались исходя из дефолтного размера входного изобр. - **224х224**
- **Fig. C** - основной блок этой сетки, bottleneck, их  2 вида, первый для сетей до 34 слоев, второй для сеток после 34 слоев, линия сбоку - shortcut(identity mapping). 
В настоящих реализациях после конв. используется пакетная нормализация и активация.
- **Fig. B** - пример 34-й архитектуры, разными цветами обозначены блоки с РАЗНЫМ размером feature map'a, используется также 2 вида shortcut'a, первый - классический, обычная передача инпута, второй(штрих) для изменения размера feature map'a, изменять он его может двумя разными методами: А - непараметр. метод, проходимся пулингом 1х1 с страйдом 2, теперь размер feature map'ов изменился но количество каналов такое же, добавляем(18, 34) нулевые/убираем(>34) feature map'ы. В - параметрический метод, он лучше, проходимся конв. 1х1 с страйдом 2(к примеру на изображении было 64 канала, прошлись 128 ядрами с страйдом 2), кол-во фильтров при этом увеличиличивает(18/34 архит.)/уменьшает(>34 архит.)(см. архитектуру) кол-во каналов на след. блоке

Количество параметров
  ![](https://github.com/kiru883/Courses/blob/master/CV%20notes/images/resnetP.PNG)

Ссылки
  - https://arxiv.org/pdf/1512.03385.pdf - ориг
  - https://arxiv.org/pdf/1603.05027.pdf - тут утверждают, что relu лучше применять ток к остаткам
  - https://github.com/keras-team/keras-applications/blob/master/keras_applications/resnet50.py - реализация от keras team
  - https://towardsdatascience.com/intuition-behind-residual-neural-networks-fa5d2996b2c7
  - https://neurohive.io/ru/vidy-nejrosetej/resnet-34-50-101/



# Segmentation
  - Unet
    - https://arxiv.org/pdf/1505.04597.pdf
